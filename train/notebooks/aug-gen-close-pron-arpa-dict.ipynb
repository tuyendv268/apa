{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monopthongs = {\n",
    "    'AO': 'ɔ',\n",
    "    'AA': 'ɑ',\n",
    "    'IY': 'i',\n",
    "    'UW': 'u',\n",
    "    'EH': 'e',\n",
    "    'IH': 'ɪ',\n",
    "    'UH': 'ʊ',\n",
    "    'AH': 'ʌ',\n",
    "    'AX': 'ə',\n",
    "    'AE': 'æ',\n",
    "}\n",
    "\n",
    "dipthongs = {\n",
    "    'EY': 'eɪ',\n",
    "    'AY': 'aɪ',\n",
    "    'OW': 'oʊ',\n",
    "    'AW': 'aʊ',\n",
    "    'OY': 'ɔɪ'\n",
    "}\n",
    "\n",
    "r_colored_vowels = {\n",
    "    'ER': 'ɜr'\n",
    "}\n",
    "\n",
    "stops = {\n",
    "    'P': 'p',\n",
    "    'B': 'b',\n",
    "    'T': 't',\n",
    "    'D': 'd',\n",
    "    'K': 'k',\n",
    "    'G': 'g',\n",
    "}\n",
    "\n",
    "affricates = {\n",
    "    'CH': 'tʃ',\n",
    "    'JH': 'dʒ',\n",
    "}\n",
    "\n",
    "fricatives = {\n",
    "    'F': 'f',\n",
    "    'V': 'v',\n",
    "    'TH': 'θ',\n",
    "    'DH': 'ð',\n",
    "    'S': 's',\n",
    "    'Z': 'z',\n",
    "    'SH': 'ʃ',\n",
    "    'ZH': 'ʒ',\n",
    "    'HH': 'h',\n",
    "}\n",
    "\n",
    "nasals = {\n",
    "    'M': 'm',\n",
    "    'N': 'n',\n",
    "    'NG': 'ŋ'\n",
    "}\n",
    "\n",
    "liquids = {\n",
    "    'L': 'l',\n",
    "    'R': 'r'\n",
    "}\n",
    "\n",
    "semivowels = {\n",
    "    'W': 'w',\n",
    "    'Y': 'j'\n",
    "}\n",
    "\n",
    "arpa_to_ipa_lookup = {}\n",
    "arpa_to_ipa_lookup.update(monopthongs)\n",
    "arpa_to_ipa_lookup.update(dipthongs)\n",
    "arpa_to_ipa_lookup.update(r_colored_vowels)\n",
    "arpa_to_ipa_lookup.update(stops)\n",
    "arpa_to_ipa_lookup.update(affricates)\n",
    "arpa_to_ipa_lookup.update(fricatives)\n",
    "arpa_to_ipa_lookup.update(nasals)\n",
    "arpa_to_ipa_lookup.update(liquids)\n",
    "arpa_to_ipa_lookup.update(semivowels)\n",
    "\n",
    "def arpa_to_ipa(arpa):\n",
    "    return ' '.join(arpa_to_ipa_lookup[phoneme] for phoneme in arpa.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/apa/train/resources/phone_dict.json\"\n",
    "phone_dict = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "print(phone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in arpa_to_ipa_lookup.items():\n",
    "    key = re.sub(\"\\d\", \" \", key).strip()\n",
    "    if key not in phone_dict:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_to_arpa = {}\n",
    "for key, value in arpa_to_ipa_lookup.items():\n",
    "    assert key not in ipa_to_arpa\n",
    "\n",
    "    ipa_to_arpa[value] = key\n",
    "\n",
    "print(ipa_to_arpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_pron_ipa_list = [\n",
    "    ('/ɪ/', '/i/'),\n",
    "    ('/e/', '/ɪ/'),\n",
    "    ('/e/', '/eɪ/'),\n",
    "    ('/æ/', '/ʌ/'),\n",
    "    ('/oʊ/', '/ɔ/'),\n",
    "    ('/ɑ/', '/oʊ/'),\n",
    "    ('/æ/', '/e/'),\n",
    "    ('/ɑ/', '/ɜr/'),\n",
    "    ('/æ/', '/ɑ/'),\n",
    "    ('/ɑ/', '/ɔ/'),\n",
    "    ('/oʊ/', '/aʊ/'),\n",
    "    ('/b/', '/v/'),\n",
    "    ('/b/', '/p/'),\n",
    "    ('/n/', '/ŋ/'),\n",
    "    ('/l/', '/r/'),\n",
    "    ('/tʃ/', '/t/'),\n",
    "    ('/s/', '/ʃ/'),\n",
    "    ('/f/', '/v/'),\n",
    "    ('/f/', '/h/'),\n",
    "    ('/f/', '/θ/'),\n",
    "    ('/s/', '/θ/'),\n",
    "    ('/ð/', '/z/'),\n",
    "    ('/dʒ/', '/z/'),\n",
    "    ('/d/', '/dʒ/'),\n",
    "    ('/f/', '/p/'),\n",
    "    ('/tʃ/', '/dʒ/'),\n",
    "    ('/tʃ/', '/ʃ/'),\n",
    "    ('/d/', '/ð/'),\n",
    "    ('/t/', '/θ/'),\n",
    "    ('/f/', '/p/'),\n",
    "    ('/k/', '/g/'),\n",
    "    ('/t/', '/d/'),\n",
    "    ('/v/', '/w/'),\n",
    "    ('/g/', '/w/'),\n",
    "    ('/h/', '/r/'),\n",
    "    ('/r/', '/w/'),\n",
    "    ('/dʒ/', '/j/'),\n",
    "    ('/k/', '/g/'),\n",
    "    ('/m/', '/n/'),\n",
    "    ('/t/', '/d/'),\n",
    "    ('/s/', '/z/'),\n",
    "    ('/n/', '/ŋ/'),\n",
    "]\n",
    "same_pron_ipa_dict = {}\n",
    "for ipa_1, ipa_2 in same_pron_ipa_list:\n",
    "    ipa_1 = re.sub(r\"\\/\", \"\", ipa_1).strip()\n",
    "    ipa_2 = re.sub(r\"\\/\", \"\", ipa_2).strip()\n",
    "\n",
    "    assert ipa_2 in ipa_to_arpa\n",
    "    assert ipa_1 in ipa_to_arpa\n",
    "\n",
    "    if ipa_1 not in same_pron_ipa_dict:\n",
    "        same_pron_ipa_dict[ipa_1] = [ipa_2, ]\n",
    "    else:\n",
    "        same_pron_ipa_dict[ipa_1].append(ipa_2)\n",
    "\n",
    "    if ipa_2 not in same_pron_ipa_dict:\n",
    "        same_pron_ipa_dict[ipa_2] = [ipa_1, ]\n",
    "    else:\n",
    "        same_pron_ipa_dict[ipa_2].append(ipa_1)\n",
    "\n",
    "\n",
    "for key in same_pron_ipa_dict.keys():\n",
    "    same_pron_ipa_dict[key] = set(same_pron_ipa_dict[key])\n",
    "\n",
    "print(same_pron_ipa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_pron_arpa_dict = {}\n",
    "for key, values in same_pron_ipa_dict.items():\n",
    "    key = ipa_to_arpa[key]\n",
    "    if key not in same_pron_arpa_dict:\n",
    "        same_pron_arpa_dict[key] = []\n",
    "    for value in values:\n",
    "        value = ipa_to_arpa[value]\n",
    "        same_pron_arpa_dict[key].append(value)\n",
    "\n",
    "print(same_pron_arpa_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/apa/train/resources/same_pron_arpa_dict.json\"\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json_obj = json.dumps(same_pron_arpa_dict, indent=4, ensure_ascii=False)\n",
    "    f.write(json_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
