{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/prep_ps_pykaldi_dev\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/prep_ps_pykaldi_dev/\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from src.dataset import PrepDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    if RED_YELLOW is not None:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":2}\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "    else:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":1}\n",
    "        RED_YELLOW = 30/50\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_data(data_dir):\n",
    "    phone_ids = np.load(f'{data_dir}/phone_ids.npy')\n",
    "    word_ids = np.load(f'{data_dir}/word_ids.npy')\n",
    "    \n",
    "    phone_scores = np.load(f'{data_dir}/phone_scores.npy')\n",
    "    word_scores = np.load(f'{data_dir}/word_scores.npy')\n",
    "    sentence_scores = np.load(f'{data_dir}/sentence_scores.npy')\n",
    "\n",
    "    durations = np.load(f'{data_dir}/duration.npy')\n",
    "    gops = np.load(f'{data_dir}/gop.npy')\n",
    "    wavlm_features = np.load(f'{data_dir}/wavlm_features.npy')\n",
    "\n",
    "    relative_positions = np.load(f'{data_dir}/relative_positions.npy')\n",
    "\n",
    "    return phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, wavlm_features, relative_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class PrepDataset(Dataset):\n",
    "    def __init__(self, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, wavlm_features, relative_positions):\n",
    "        self.phone_ids = phone_ids\n",
    "        self.word_ids = word_ids\n",
    "\n",
    "        self.phone_scores = phone_scores\n",
    "        self.word_scores = word_scores\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "        self.gops = gops\n",
    "        self.durations = durations\n",
    "        self.wavlm_features = wavlm_features\n",
    "        self.relative_positions = relative_positions\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.phone_ids.shape[0]\n",
    "    \n",
    "    def parse_data(self, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, wavlm_features, relative_positions):\n",
    "        phone_ids = torch.tensor(phone_ids)\n",
    "        word_ids = torch.tensor(word_ids)\n",
    "\n",
    "        phone_scores = torch.tensor(phone_scores).float().clone()\n",
    "        word_scores = torch.tensor(word_scores).float().clone()\n",
    "        sentence_scores = torch.tensor(sentence_scores).float().clone()\n",
    "\n",
    "        phone_scores[phone_scores != -1] /= 50\n",
    "        word_scores[word_scores != -1] /= 50\n",
    "        sentence_scores /= 50\n",
    "\n",
    "        durations = torch.tensor(durations)\n",
    "        gops = torch.tensor(gops)\n",
    "        wavlm_features = torch.tensor(wavlm_features)\n",
    "        relative_positions = torch.tensor(relative_positions)\n",
    "\n",
    "        features = torch.concat([gops, durations.unsqueeze(-1), wavlm_features], dim=-1)        \n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"phone_ids\": phone_ids,\n",
    "            \"word_ids\": word_ids,\n",
    "            \"phone_scores\":phone_scores,\n",
    "            \"word_scores\":word_scores,\n",
    "            \"sentence_scores\":sentence_scores,\n",
    "            \"relative_positions\": relative_positions\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phone_ids = self.phone_ids[index]\n",
    "        word_ids = self.word_ids[index]\n",
    "\n",
    "        phone_scores = self.phone_scores[index]\n",
    "        word_scores = self.word_scores[index]\n",
    "        sentence_scores = self.sentence_scores[index]\n",
    "\n",
    "        gops = self.gops[index]\n",
    "        durations = self.durations[index]\n",
    "        wavlm_features = self.wavlm_features[index]\n",
    "        relative_positions = self.relative_positions[index]\n",
    "\n",
    "        return self.parse_data(\n",
    "            phone_ids=phone_ids,\n",
    "            word_ids=word_ids,\n",
    "            phone_scores=phone_scores,\n",
    "            word_scores=word_scores,\n",
    "            sentence_scores=sentence_scores,\n",
    "            gops=gops,\n",
    "            durations=durations,\n",
    "            wavlm_features=wavlm_features,\n",
    "            relative_positions=relative_positions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "# from src.model import GOPT\n",
    "\n",
    "train_dir = \"/data/codes/apa/train/exps/features/train\"\n",
    "\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features, relative_positions = load_data(train_dir)\n",
    "trainset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features, relative_positions\n",
    "    )\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=False)\n",
    "\n",
    "test_dir = \"/data/codes/apa/train/exps/features/test\"\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features, relative_positions = load_data(test_dir)\n",
    "testset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features, relative_positions\n",
    "    )\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    def norm_cdf(x):\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "        tensor.erfinv_()\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, drop_rate=0.1) -> None:\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "\n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.rand(hidden_dim).uniform_(-0.1, 0.1))\n",
    "        \n",
    "        self.score_proj = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        score = self.score_proj(torch.tanh(self.key_proj(key) + self.query_proj(query) + self.bias)).squeeze(-1)\n",
    "        attn = F.softmax(score, dim=-1)\n",
    "        context = torch.bmm(attn.unsqueeze(1), value)\n",
    "        return context, attn\n",
    "\n",
    "class DepthwiseSeparableConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.depthwise_conv = nn.Conv1d(\n",
    "            in_channels=in_channels, out_channels=in_channels,\n",
    "            kernel_size=kernel_size, groups=in_channels, \n",
    "            padding=kernel_size//2, bias=False\n",
    "        )\n",
    "\n",
    "        self.pointwise_conv = nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        x = x.transpose(1,2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: `embeddings`, shape (batch, max_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            `encoder input`, shape (batch, max_len, d_model)\n",
    "        \"\"\"\n",
    "        return self.pe[:, : x.size(1)]\n",
    "    \n",
    "class PrepModel(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth, input_dim=84, max_length=50, num_phone=40, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_phone = num_phone\n",
    "\n",
    "        # self.pos_embed = nn.Parameter(torch.zeros(1, max_length+1, self.embed_dim))\n",
    "        self.pos_embed = PositionalEncoding(d_model=self.embed_dim, max_len=max_length)\n",
    "        # trunc_normal_(self.pos_embed, std=.02)\n",
    "        \n",
    "        self.phn_proj = nn.Linear(num_phone, embed_dim)\n",
    "        self.in_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        self.phone_encoders = nn.ModuleList(\n",
    "            [\n",
    "                Block(dim=embed_dim, num_heads=num_heads) \n",
    "                for i in range(depth)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.ds_conv = DepthwiseSeparableConvolution(\n",
    "            in_channels=embed_dim, \n",
    "            out_channels=embed_dim, \n",
    "            kernel_size=3\n",
    "        )\n",
    "        \n",
    "        self.word_encoders = nn.ModuleList(\n",
    "            [\n",
    "                Block(dim=embed_dim, num_heads=num_heads) \n",
    "                for i in range(1)\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        self.rel_pos_embed = nn.Embedding(\n",
    "            num_embeddings=5, embedding_dim=embed_dim)\n",
    "        \n",
    "        self.utt_encoders = nn.ModuleList(\n",
    "            [\n",
    "                Block(dim=embed_dim, num_heads=num_heads) \n",
    "                for i in range(1)\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        self.utt_addi = AdditiveAttention(hidden_dim=embed_dim)\n",
    "\n",
    "        self.phone_head = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.utt_head = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.word_head = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "    def forward(self, x, phn, rel_pos):\n",
    "        batch_size, seq_length, embedd_dim = x.shape[0], x.shape[1], x.shape[2]\n",
    "\n",
    "        phn_one_hot = torch.nn.functional.one_hot(phn.long()+1, num_classes=self.num_phone).float()\n",
    "        phn_embed = self.phn_proj(phn_one_hot)\n",
    "\n",
    "        if self.embed_dim != self.input_dim:\n",
    "            x = self.in_proj(x)\n",
    "\n",
    "        # p_x = x + phn_embed + self.pos_embed[:,:seq_length,:]\n",
    "        p_x = x + phn_embed + self.pos_embed(x)\n",
    "        for block in self.phone_encoders:\n",
    "            p_x = block(p_x)\n",
    "        phone_score = self.phone_head(p_x)\n",
    "\n",
    "        w_x = p_x + self.rel_pos_embed(rel_pos)\n",
    "        w_x = self.ds_conv(w_x)\n",
    "        for block in self.word_encoders:\n",
    "            w_x = block(w_x)\n",
    "        \n",
    "        word_score = self.word_head(w_x)\n",
    "\n",
    "        for block in self.utt_encoders:\n",
    "            w_x = block(w_x)\n",
    "\n",
    "        u_x = p_x + w_x\n",
    "\n",
    "        u_x, attn = self.utt_addi(query=u_x, key=u_x, value=u_x)\n",
    "        utt_score = self.utt_head(u_x.squeeze(1))\n",
    "\n",
    "        return utt_score, phone_score, word_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=853\n",
    "num_phone=43\n",
    "max_length=128\n",
    "\n",
    "lr=1e-3\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = PrepModel(\n",
    "    embed_dim=embed_dim, num_heads=num_heads, \n",
    "    depth=depth, input_dim=input_dim, \n",
    "    max_length=max_length, num_phone=num_phone, dropout=0.1).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(predict, target):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(predict.shape[0]):\n",
    "        for j in range(predict.shape[1]):\n",
    "            if target[i, j] >= 0:\n",
    "                preds.append(predict[i, j])\n",
    "                targs.append(target[i, j])\n",
    "    targs = np.array(targs)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    mse = np.mean((targs - preds) ** 2)\n",
    "    mae = np.mean(np.abs(targs - preds))\n",
    "    corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    return mse, mae, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_wrd(predict, target, word_id):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(target.shape[0]):\n",
    "        prev_w_id, start_id = 0, 0\n",
    "        # for each token\n",
    "        for j in range(target.shape[1]):\n",
    "            cur_w_id = word_id[i, j].int()\n",
    "            # if a new word\n",
    "            if cur_w_id != prev_w_id:\n",
    "                # average each phone belongs to the word\n",
    "                preds.append(np.mean(predict[i, start_id: j].numpy(), axis=0))\n",
    "                targs.append(np.mean(target[i, start_id: j].numpy(), axis=0))\n",
    "\n",
    "                if cur_w_id == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    prev_w_id = cur_w_id\n",
    "                    start_id = j\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    targs = np.array(targs).round(2)\n",
    "\n",
    "    word_mse = np.mean((preds - targs) ** 2)\n",
    "    wrd_mae = np.mean(np.abs(preds - targs))\n",
    "    word_corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    \n",
    "    return word_mse, wrd_mae, word_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_utt(predict, target):\n",
    "    utt_mse = np.mean(((predict[:, 0] - target[:, 0]) ** 2).numpy())\n",
    "    utt_mae = np.mean((np.abs(predict[:, 0] - target[:, 0])).numpy())\n",
    "    \n",
    "    utt_corr = np.corrcoef(predict[:, 0], target[:, 0])[0, 1]\n",
    "    return utt_mse, utt_mae, utt_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch, device):\n",
    "    features = batch[\"features\"].to(device)\n",
    "    phone_ids = batch[\"phone_ids\"].to(device)\n",
    "    relative_positions = batch[\"relative_positions\"].to(device)\n",
    "    word_ids = batch[\"word_ids\"]\n",
    "    \n",
    "    phone_labels = batch[\"phone_scores\"].to(device)\n",
    "    word_labels = batch[\"word_scores\"].to(device)\n",
    "    utterance_labels = batch[\"sentence_scores\"].to(device)\n",
    "\n",
    "    return features, phone_ids, word_ids, relative_positions, phone_labels, word_labels, utterance_labels\n",
    "\n",
    "def to_cpu(preds, labels):\n",
    "    preds = preds.detach().cpu().squeeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    \n",
    "    return label[index], pred[index]\n",
    "\n",
    "def save_confusion_matrix_figure(\n",
    "        fig_path, pred_path, label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    \n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(\n",
    "        torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    predicted = convert_score_to_color(\n",
    "        torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    if RED_YELLOW is not None:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    else:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"CORRECT\", \"INCORRECT\"])\n",
    "\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.savefig(fig_path) \n",
    "    plt.close()\n",
    "\n",
    "def save(epoch, output_dir, model, optimizer, phone_desicion_result, \\\n",
    "    phone_predicts, phone_labels, word_predicts, word_labels, utterance_predicts, utterance_labels):\n",
    "    \n",
    "    model_path = f'{output_dir}/model.pt'\n",
    "    optimizer_path = f'{output_dir}/optimizer.pt'\n",
    "    phone_desicion_result_path = f'{output_dir}/phone_result'\n",
    "\n",
    "    phone_predict_path = f'{output_dir}/phn_pred.npy'\n",
    "    phone_label_path = f'{output_dir}/phn_label.npy'\n",
    "    word_predict_path = f'{output_dir}/wrd_pred.npy'\n",
    "    word_label_path = f'{output_dir}/wrd_label.npy'\n",
    "    utterance_predict_path = f'{output_dir}/utt_pred.npy'\n",
    "    utterance_label_path = f'{output_dir}/utt_label.npy'\n",
    "\n",
    "    three_class_fig_path = f'{output_dir}/confusion_matrix_three_class.png'\n",
    "    two_class_fig_path = f'{output_dir}/confusion_matrix_two_class.png'\n",
    "\n",
    "    with open(phone_desicion_result_path, \"w\") as f:\n",
    "        f.write(phone_desicion_result)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    np.save(phone_predict_path, phone_predicts)\n",
    "    np.save(phone_label_path, phone_labels)\n",
    "    np.save(word_predict_path, word_predicts)\n",
    "    np.save(word_label_path, word_labels)\n",
    "    np.save(utterance_predict_path, utterance_predicts)\n",
    "    np.save(utterance_label_path, utterance_labels)\n",
    "    save_confusion_matrix_figure(three_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=40/50)\n",
    "    save_confusion_matrix_figure(two_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=None)\n",
    "\n",
    "    print(f'Save state dict and result to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(epoch, gopt_model, testloader, best_mse, ckpt_dir):\n",
    "    gopt_model.eval()\n",
    "    A_phn, A_phn_target = [], []\n",
    "    A_utt, A_utt_target = [], []\n",
    "    A_wrd, A_wrd_target, A_wrd_id = [], [], []\n",
    "\n",
    "    for batch in testloader:\n",
    "        features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "        \n",
    "        phone_preds, phone_labels = to_cpu(phone_preds, phone_labels)\n",
    "        word_preds, word_labels = to_cpu(word_preds, word_labels)\n",
    "        utterance_preds, utterance_labels = to_cpu(utterance_preds, utterance_labels)\n",
    "        \n",
    "        A_phn.append(phone_preds), A_phn_target.append(phone_labels)\n",
    "        A_utt.append(utterance_preds), A_utt_target.append(utterance_labels)\n",
    "        A_wrd.append(word_preds), A_wrd_target.append(word_labels), A_wrd_id.append(word_ids)\n",
    "    \n",
    "    # phone level\n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    decision_result = calculate_phone_decision_result(A_phn, A_phn_target)\n",
    "\n",
    "    # word level\n",
    "    A_word, A_word_target, A_word_id = torch.vstack(A_wrd), torch.vstack(A_wrd_target), torch.vstack(A_wrd_id) \n",
    "\n",
    "    # utterance level\n",
    "    A_utt, A_utt_target = torch.vstack(A_utt), torch.vstack(A_utt_target)\n",
    "\n",
    "    # valid_token_mse, mae, corr\n",
    "    phn_mse, phn_mae, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    word_mse, wrd_mae, word_corr = valid_wrd(A_word, A_word_target, A_word_id)\n",
    "    utt_mse, utt_mae, utt_corr = valid_utt(A_utt, A_utt_target)\n",
    "\n",
    "    if phn_mse < best_mse:\n",
    "        best_mse = phn_mse\n",
    "    ckpt_dir = f'{ckpt_dir}/ckpts-eph={epoch}-mse={round(phn_mse, 4)}'\n",
    "    os.makedirs(ckpt_dir)\n",
    "    \n",
    "    save(\n",
    "        epoch=epoch,\n",
    "        output_dir=ckpt_dir, \n",
    "        model=gopt_model, \n",
    "        optimizer=optimizer, \n",
    "        phone_desicion_result=decision_result, \n",
    "        phone_predicts=A_phn.numpy(), \n",
    "        phone_labels=A_phn_target.numpy(), \n",
    "        word_predicts=A_word.numpy(), \n",
    "        word_labels=A_word_target.numpy(), \n",
    "        utterance_predicts=A_utt.numpy(), \n",
    "        utterance_labels=A_utt_target.numpy()\n",
    "    )\n",
    "    \n",
    "    with open(f'{ckpt_dir}/pcc', \"w\") as f:\n",
    "        f.write(\"Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(phn_mse, phn_mae, phn_corr))\n",
    "        f.write(\"Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(word_mse, wrd_mae, word_corr))\n",
    "        f.write(\"Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    print(f\"### Validation result (epoch={epoch})\")\n",
    "    print(\"  Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(phn_mse, phn_mae, phn_corr))\n",
    "    print(\"   Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(word_mse, wrd_mae, word_corr))\n",
    "    print(\"    Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    return {\n",
    "        \"phn_mse\": phn_mse, \n",
    "        \"phn_mae\": phn_mae,\n",
    "        \"phn_corr\": phn_corr,\n",
    "        \"word_mse\": word_mse,\n",
    "        \"wrd_mae\": wrd_mae,\n",
    "        \"word_corr\": word_corr,\n",
    "        \"utt_mse\": utt_mse,\n",
    "        \"utt_mae\": utt_mae,\n",
    "        \"utt_corr\": utt_corr,\n",
    "        \"best_mse\": best_mse\n",
    "    }\n",
    "\n",
    "def calculate_phone_decision_result(A_phn, A_phn_target):\n",
    "    indices = A_phn_target != -1\n",
    "    _label = A_phn_target[indices].clone()\n",
    "    _pred = A_phn[indices].clone()\n",
    "\n",
    "    converted_pred = convert_score_to_color(_pred).view(-1)\n",
    "    converted_label = convert_score_to_color(_label).view(-1)\n",
    "\n",
    "    result = classification_report(y_true=converted_label, y_pred=converted_pred)\n",
    "    print(\"### F1 Score: \\n\", result)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "    # loss_utt = torch.tensor(0)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 94/15149 [00:00<01:31, 164.51it/s, loss=0.665, loss_phn=0.335, loss_utt=0.125, loss_word=0.205, lr=0.001]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 199.97it/s, loss=0.248, loss_phn=0.119, loss_utt=0.0388, loss_word=0.0912, lr=0.001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.89     59975\n",
      "         1.0       0.18      0.53      0.27      5524\n",
      "         2.0       0.77      0.42      0.55     10340\n",
      "\n",
      "    accuracy                           0.76     75839\n",
      "   macro avg       0.63      0.60      0.57     75839\n",
      "weighted avg       0.86      0.76      0.79     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=0-mse=0.18930000066757202\n",
      "### Validation result (epoch=0)\n",
      "  Phone level:  MSE=0.189  MAE=0.269  PCC=0.722 \n",
      "   Word level:  MSE=0.137  MAE=0.269  PCC=0.729 \n",
      "    Utt level:  MSE=0.048  MAE=0.169  PCC=0.792 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 204.18it/s, loss=0.347, loss_phn=0.182, loss_utt=0.0182, loss_word=0.147, lr=0.001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.89     59975\n",
      "         1.0       0.19      0.56      0.28      5524\n",
      "         2.0       0.80      0.45      0.57     10340\n",
      "\n",
      "    accuracy                           0.77     75839\n",
      "   macro avg       0.64      0.62      0.58     75839\n",
      "weighted avg       0.87      0.77      0.80     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=1-mse=0.17229999601840973\n",
      "### Validation result (epoch=1)\n",
      "  Phone level:  MSE=0.172  MAE=0.244  PCC=0.752 \n",
      "   Word level:  MSE=0.123  MAE=0.246  PCC=0.756 \n",
      "    Utt level:  MSE=0.042  MAE=0.160  PCC=0.812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 204.02it/s, loss=0.163, loss_phn=0.14, loss_utt=0.0137, loss_word=0.00856, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90     59975\n",
      "         1.0       0.20      0.58      0.29      5524\n",
      "         2.0       0.84      0.41      0.55     10340\n",
      "\n",
      "    accuracy                           0.78     75839\n",
      "   macro avg       0.66      0.62      0.58     75839\n",
      "weighted avg       0.88      0.78      0.81     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=2-mse=0.1647000014781952\n",
      "### Validation result (epoch=2)\n",
      "  Phone level:  MSE=0.165  MAE=0.257  PCC=0.765 \n",
      "   Word level:  MSE=0.117  MAE=0.248  PCC=0.767 \n",
      "    Utt level:  MSE=0.042  MAE=0.161  PCC=0.817 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:13<00:00, 204.83it/s, loss=0.378, loss_phn=0.17, loss_utt=0.0908, loss_word=0.118, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.87      0.90     59975\n",
      "         1.0       0.20      0.57      0.30      5524\n",
      "         2.0       0.85      0.42      0.56     10340\n",
      "\n",
      "    accuracy                           0.78     75839\n",
      "   macro avg       0.66      0.62      0.59     75839\n",
      "weighted avg       0.88      0.78      0.81     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=3-mse=0.16179999709129333\n",
      "### Validation result (epoch=3)\n",
      "  Phone level:  MSE=0.162  MAE=0.234  PCC=0.770 \n",
      "   Word level:  MSE=0.126  MAE=0.244  PCC=0.764 \n",
      "    Utt level:  MSE=0.045  MAE=0.162  PCC=0.823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 204.26it/s, loss=0.37, loss_phn=0.25, loss_utt=0.0483, loss_word=0.0718, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90     59975\n",
      "         1.0       0.20      0.58      0.30      5524\n",
      "         2.0       0.82      0.47      0.60     10340\n",
      "\n",
      "    accuracy                           0.78     75839\n",
      "   macro avg       0.66      0.64      0.60     75839\n",
      "weighted avg       0.88      0.78      0.81     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=4-mse=0.15760000050067902\n",
      "### Validation result (epoch=4)\n",
      "  Phone level:  MSE=0.158  MAE=0.231  PCC=0.777 \n",
      "   Word level:  MSE=0.113  MAE=0.242  PCC=0.778 \n",
      "    Utt level:  MSE=0.042  MAE=0.159  PCC=0.813 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 203.13it/s, loss=0.453, loss_phn=0.163, loss_utt=0.139, loss_word=0.152, lr=0.001]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90     59975\n",
      "         1.0       0.20      0.58      0.30      5524\n",
      "         2.0       0.83      0.47      0.60     10340\n",
      "\n",
      "    accuracy                           0.78     75839\n",
      "   macro avg       0.66      0.63      0.60     75839\n",
      "weighted avg       0.88      0.78      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=5-mse=0.15379999577999115\n",
      "### Validation result (epoch=5)\n",
      "  Phone level:  MSE=0.154  MAE=0.230  PCC=0.781 \n",
      "   Word level:  MSE=0.112  MAE=0.246  PCC=0.780 \n",
      "    Utt level:  MSE=0.039  MAE=0.157  PCC=0.826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 203.90it/s, loss=0.29, loss_phn=0.121, loss_utt=0.0714, loss_word=0.0974, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.84      0.90     59975\n",
      "         1.0       0.20      0.60      0.30      5524\n",
      "         2.0       0.81      0.49      0.61     10340\n",
      "\n",
      "    accuracy                           0.78     75839\n",
      "   macro avg       0.65      0.65      0.60     75839\n",
      "weighted avg       0.88      0.78      0.81     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=6-mse=0.15320000052452087\n",
      "### Validation result (epoch=6)\n",
      "  Phone level:  MSE=0.153  MAE=0.244  PCC=0.783 \n",
      "   Word level:  MSE=0.113  MAE=0.256  PCC=0.783 \n",
      "    Utt level:  MSE=0.040  MAE=0.158  PCC=0.826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 204.18it/s, loss=0.276, loss_phn=0.123, loss_utt=0.0509, loss_word=0.103, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90     59975\n",
      "         1.0       0.21      0.60      0.31      5524\n",
      "         2.0       0.84      0.46      0.59     10340\n",
      "\n",
      "    accuracy                           0.79     75839\n",
      "   macro avg       0.67      0.64      0.60     75839\n",
      "weighted avg       0.88      0.79      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=7-mse=0.14970000088214874\n",
      "### Validation result (epoch=7)\n",
      "  Phone level:  MSE=0.150  MAE=0.235  PCC=0.788 \n",
      "   Word level:  MSE=0.108  MAE=0.233  PCC=0.790 \n",
      "    Utt level:  MSE=0.038  MAE=0.152  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 203.95it/s, loss=0.315, loss_phn=0.184, loss_utt=0.044, loss_word=0.087, lr=0.001]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.83      0.49      0.62     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.64      0.61     75839\n",
      "weighted avg       0.88      0.80      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=8-mse=0.14820000529289246\n",
      "### Validation result (epoch=8)\n",
      "  Phone level:  MSE=0.148  MAE=0.219  PCC=0.791 \n",
      "   Word level:  MSE=0.109  MAE=0.238  PCC=0.786 \n",
      "    Utt level:  MSE=0.042  MAE=0.157  PCC=0.826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.21it/s, loss=0.352, loss_phn=0.198, loss_utt=0.0735, loss_word=0.0803, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.83      0.50      0.62     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.61     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=9-mse=0.14830000698566437\n",
      "### Validation result (epoch=9)\n",
      "  Phone level:  MSE=0.148  MAE=0.218  PCC=0.791 \n",
      "   Word level:  MSE=0.107  MAE=0.231  PCC=0.791 \n",
      "    Utt level:  MSE=0.039  MAE=0.153  PCC=0.826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.85it/s, loss=0.23, loss_phn=0.149, loss_utt=0.0376, loss_word=0.0436, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.83      0.50      0.62     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.61     75839\n",
      "weighted avg       0.88      0.80      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=10-mse=0.14720000326633453\n",
      "### Validation result (epoch=10)\n",
      "  Phone level:  MSE=0.147  MAE=0.220  PCC=0.792 \n",
      "   Word level:  MSE=0.108  MAE=0.235  PCC=0.790 \n",
      "    Utt level:  MSE=0.040  MAE=0.151  PCC=0.831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 203.09it/s, loss=0.145, loss_phn=0.0721, loss_utt=0.00941, loss_word=0.063, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.56      0.30      5524\n",
      "         2.0       0.81      0.52      0.63     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.61     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=11-mse=0.14900000393390656\n",
      "### Validation result (epoch=11)\n",
      "  Phone level:  MSE=0.149  MAE=0.218  PCC=0.790 \n",
      "   Word level:  MSE=0.110  MAE=0.222  PCC=0.786 \n",
      "    Utt level:  MSE=0.039  MAE=0.153  PCC=0.829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.98it/s, loss=0.29, loss_phn=0.151, loss_utt=0.0595, loss_word=0.0792, lr=0.0008]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.83      0.50      0.62     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.67      0.65      0.61     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=12-mse=0.1451999992132187\n",
      "### Validation result (epoch=12)\n",
      "  Phone level:  MSE=0.145  MAE=0.214  PCC=0.796 \n",
      "   Word level:  MSE=0.106  MAE=0.231  PCC=0.793 \n",
      "    Utt level:  MSE=0.039  MAE=0.152  PCC=0.828 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 203.14it/s, loss=0.435, loss_phn=0.214, loss_utt=0.0884, loss_word=0.132, lr=0.0008]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.56      0.31      5524\n",
      "         2.0       0.84      0.49      0.62     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.67      0.64      0.61     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=13-mse=0.14740000665187836\n",
      "### Validation result (epoch=13)\n",
      "  Phone level:  MSE=0.147  MAE=0.219  PCC=0.794 \n",
      "   Word level:  MSE=0.107  MAE=0.232  PCC=0.791 \n",
      "    Utt level:  MSE=0.038  MAE=0.150  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.17it/s, loss=0.249, loss_phn=0.0989, loss_utt=0.0707, loss_word=0.0796, lr=0.0008]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.82      0.51      0.63     10340\n",
      "\n",
      "    accuracy                           0.79     75839\n",
      "   macro avg       0.66      0.65      0.61     75839\n",
      "weighted avg       0.88      0.79      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=14-mse=0.1468999981880188\n",
      "### Validation result (epoch=14)\n",
      "  Phone level:  MSE=0.147  MAE=0.227  PCC=0.793 \n",
      "   Word level:  MSE=0.106  MAE=0.233  PCC=0.792 \n",
      "    Utt level:  MSE=0.039  MAE=0.154  PCC=0.825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.84it/s, loss=0.754, loss_phn=0.479, loss_utt=0.107, loss_word=0.168, lr=0.00064]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.56      0.31      5524\n",
      "         2.0       0.82      0.52      0.64     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=15-mse=0.14350000023841858\n",
      "### Validation result (epoch=15)\n",
      "  Phone level:  MSE=0.144  MAE=0.218  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.227  PCC=0.795 \n",
      "    Utt level:  MSE=0.037  MAE=0.147  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.88it/s, loss=0.285, loss_phn=0.16, loss_utt=0.0514, loss_word=0.0729, lr=0.00064]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.83      0.51      0.63     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=16-mse=0.14480000734329224\n",
      "### Validation result (epoch=16)\n",
      "  Phone level:  MSE=0.145  MAE=0.219  PCC=0.796 \n",
      "   Word level:  MSE=0.105  MAE=0.222  PCC=0.795 \n",
      "    Utt level:  MSE=0.037  MAE=0.146  PCC=0.841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.35it/s, loss=0.289, loss_phn=0.128, loss_utt=0.101, loss_word=0.0599, lr=0.00064]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.56      0.31      5524\n",
      "         2.0       0.81      0.53      0.64     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=17-mse=0.1453000009059906\n",
      "### Validation result (epoch=17)\n",
      "  Phone level:  MSE=0.145  MAE=0.214  PCC=0.796 \n",
      "   Word level:  MSE=0.105  MAE=0.226  PCC=0.795 \n",
      "    Utt level:  MSE=0.037  MAE=0.149  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.94it/s, loss=0.271, loss_phn=0.132, loss_utt=0.0515, loss_word=0.0869, lr=0.000512]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     59975\n",
      "         1.0       0.21      0.57      0.30      5524\n",
      "         2.0       0.80      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.79     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.79      0.82     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=18-mse=0.1453000009059906\n",
      "### Validation result (epoch=18)\n",
      "  Phone level:  MSE=0.145  MAE=0.221  PCC=0.796 \n",
      "   Word level:  MSE=0.105  MAE=0.229  PCC=0.794 \n",
      "    Utt level:  MSE=0.037  MAE=0.150  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.11it/s, loss=0.252, loss_phn=0.168, loss_utt=0.0409, loss_word=0.0435, lr=0.000512]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.57      0.32      5524\n",
      "         2.0       0.83      0.51      0.63     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.67      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=19-mse=0.14219999313354492\n",
      "### Validation result (epoch=19)\n",
      "  Phone level:  MSE=0.142  MAE=0.212  PCC=0.800 \n",
      "   Word level:  MSE=0.106  MAE=0.223  PCC=0.796 \n",
      "    Utt level:  MSE=0.040  MAE=0.152  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.91it/s, loss=0.215, loss_phn=0.109, loss_utt=0.0374, loss_word=0.0687, lr=0.000512]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.91     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.82      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=20-mse=0.14300000667572021\n",
      "### Validation result (epoch=20)\n",
      "  Phone level:  MSE=0.143  MAE=0.218  PCC=0.799 \n",
      "   Word level:  MSE=0.104  MAE=0.222  PCC=0.795 \n",
      "    Utt level:  MSE=0.037  MAE=0.149  PCC=0.837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.55it/s, loss=0.273, loss_phn=0.112, loss_utt=0.089, loss_word=0.0721, lr=0.00041]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90     59975\n",
      "         1.0       0.21      0.56      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=21-mse=0.1428000032901764\n",
      "### Validation result (epoch=21)\n",
      "  Phone level:  MSE=0.143  MAE=0.218  PCC=0.800 \n",
      "   Word level:  MSE=0.105  MAE=0.228  PCC=0.796 \n",
      "    Utt level:  MSE=0.037  MAE=0.152  PCC=0.838 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.91it/s, loss=0.28, loss_phn=0.178, loss_utt=0.0404, loss_word=0.0623, lr=0.00041]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.80      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=22-mse=0.14229999482631683\n",
      "### Validation result (epoch=22)\n",
      "  Phone level:  MSE=0.142  MAE=0.213  PCC=0.801 \n",
      "   Word level:  MSE=0.104  MAE=0.220  PCC=0.797 \n",
      "    Utt level:  MSE=0.037  MAE=0.148  PCC=0.837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.01it/s, loss=0.215, loss_phn=0.169, loss_utt=0.0197, loss_word=0.0261, lr=0.00041]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.82      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=23-mse=0.14309999346733093\n",
      "### Validation result (epoch=23)\n",
      "  Phone level:  MSE=0.143  MAE=0.208  PCC=0.800 \n",
      "   Word level:  MSE=0.105  MAE=0.217  PCC=0.796 \n",
      "    Utt level:  MSE=0.041  MAE=0.153  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.43it/s, loss=0.281, loss_phn=0.153, loss_utt=0.0129, loss_word=0.115, lr=0.000328]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.91     59975\n",
      "         1.0       0.21      0.58      0.31      5524\n",
      "         2.0       0.83      0.52      0.64     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.67      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=24-mse=0.14169999957084656\n",
      "### Validation result (epoch=24)\n",
      "  Phone level:  MSE=0.142  MAE=0.220  PCC=0.801 \n",
      "   Word level:  MSE=0.104  MAE=0.226  PCC=0.796 \n",
      "    Utt level:  MSE=0.037  MAE=0.150  PCC=0.837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.11it/s, loss=0.273, loss_phn=0.179, loss_utt=0.0192, loss_word=0.0744, lr=0.000328]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.55      0.31      5524\n",
      "         2.0       0.81      0.55      0.65     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=25-mse=0.14229999482631683\n",
      "### Validation result (epoch=25)\n",
      "  Phone level:  MSE=0.142  MAE=0.214  PCC=0.801 \n",
      "   Word level:  MSE=0.104  MAE=0.225  PCC=0.797 \n",
      "    Utt level:  MSE=0.038  MAE=0.150  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.81it/s, loss=0.242, loss_phn=0.0928, loss_utt=0.0818, loss_word=0.0673, lr=0.000328]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.92     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.82      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.84     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=26-mse=0.14329999685287476\n",
      "### Validation result (epoch=26)\n",
      "  Phone level:  MSE=0.143  MAE=0.208  PCC=0.800 \n",
      "   Word level:  MSE=0.105  MAE=0.216  PCC=0.796 \n",
      "    Utt level:  MSE=0.039  MAE=0.149  PCC=0.840 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.26it/s, loss=0.324, loss_phn=0.215, loss_utt=0.0524, loss_word=0.0572, lr=0.000262]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=27-mse=0.14270000159740448\n",
      "### Validation result (epoch=27)\n",
      "  Phone level:  MSE=0.143  MAE=0.213  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.219  PCC=0.796 \n",
      "    Utt level:  MSE=0.037  MAE=0.147  PCC=0.836 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.66it/s, loss=0.174, loss_phn=0.106, loss_utt=0.0408, loss_word=0.0273, lr=0.000262]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.90     59975\n",
      "         1.0       0.21      0.57      0.31      5524\n",
      "         2.0       0.81      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.79     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.79      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=28-mse=0.14270000159740448\n",
      "### Validation result (epoch=28)\n",
      "  Phone level:  MSE=0.143  MAE=0.220  PCC=0.800 \n",
      "   Word level:  MSE=0.105  MAE=0.223  PCC=0.795 \n",
      "    Utt level:  MSE=0.037  MAE=0.148  PCC=0.836 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.40it/s, loss=0.213, loss_phn=0.139, loss_utt=0.0188, loss_word=0.0552, lr=0.000262]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=29-mse=0.14329999685287476\n",
      "### Validation result (epoch=29)\n",
      "  Phone level:  MSE=0.143  MAE=0.212  PCC=0.799 \n",
      "   Word level:  MSE=0.104  MAE=0.221  PCC=0.797 \n",
      "    Utt level:  MSE=0.038  MAE=0.150  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.90it/s, loss=0.344, loss_phn=0.212, loss_utt=0.0354, loss_word=0.0966, lr=0.00021]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.81      0.55      0.65     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=30-mse=0.14219999313354492\n",
      "### Validation result (epoch=30)\n",
      "  Phone level:  MSE=0.142  MAE=0.213  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.220  PCC=0.797 \n",
      "    Utt level:  MSE=0.038  MAE=0.150  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:14<00:00, 202.77it/s, loss=0.363, loss_phn=0.157, loss_utt=0.0618, loss_word=0.144, lr=0.00021]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.55      0.31      5524\n",
      "         2.0       0.81      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=31-mse=0.14309999346733093\n",
      "### Validation result (epoch=31)\n",
      "  Phone level:  MSE=0.143  MAE=0.216  PCC=0.799 \n",
      "   Word level:  MSE=0.105  MAE=0.221  PCC=0.796 \n",
      "    Utt level:  MSE=0.038  MAE=0.150  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.36it/s, loss=0.287, loss_phn=0.156, loss_utt=0.0435, loss_word=0.087, lr=0.00021]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.82      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=32-mse=0.14219999313354492\n",
      "### Validation result (epoch=32)\n",
      "  Phone level:  MSE=0.142  MAE=0.215  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.221  PCC=0.797 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.81it/s, loss=0.307, loss_phn=0.117, loss_utt=0.0963, loss_word=0.0928, lr=0.000168]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.55      0.65     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=33-mse=0.14329999685287476\n",
      "### Validation result (epoch=33)\n",
      "  Phone level:  MSE=0.143  MAE=0.212  PCC=0.799 \n",
      "   Word level:  MSE=0.104  MAE=0.220  PCC=0.796 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.11it/s, loss=0.0928, loss_phn=0.0617, loss_utt=0.0121, loss_word=0.019, lr=0.000168]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=34-mse=0.14239999651908875\n",
      "### Validation result (epoch=34)\n",
      "  Phone level:  MSE=0.142  MAE=0.212  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.219  PCC=0.798 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.830 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:16<00:00, 199.32it/s, loss=0.205, loss_phn=0.161, loss_utt=0.0109, loss_word=0.0322, lr=0.000168]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.56      0.31      5524\n",
      "         2.0       0.81      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=35-mse=0.14239999651908875\n",
      "### Validation result (epoch=35)\n",
      "  Phone level:  MSE=0.142  MAE=0.213  PCC=0.801 \n",
      "   Word level:  MSE=0.104  MAE=0.221  PCC=0.796 \n",
      "    Utt level:  MSE=0.037  MAE=0.147  PCC=0.837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.86it/s, loss=0.25, loss_phn=0.157, loss_utt=0.045, loss_word=0.048, lr=0.000134]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.81      0.55      0.65     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.65      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=36-mse=0.14309999346733093\n",
      "### Validation result (epoch=36)\n",
      "  Phone level:  MSE=0.143  MAE=0.214  PCC=0.799 \n",
      "   Word level:  MSE=0.105  MAE=0.221  PCC=0.795 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.92it/s, loss=0.37, loss_phn=0.193, loss_utt=0.0829, loss_word=0.0942, lr=0.000134]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=37-mse=0.14239999651908875\n",
      "### Validation result (epoch=37)\n",
      "  Phone level:  MSE=0.142  MAE=0.211  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.218  PCC=0.796 \n",
      "    Utt level:  MSE=0.039  MAE=0.148  PCC=0.829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 199.80it/s, loss=0.194, loss_phn=0.169, loss_utt=0.0103, loss_word=0.015, lr=0.000134]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.21      0.55      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.80     75839\n",
      "   macro avg       0.66      0.66      0.62     75839\n",
      "weighted avg       0.88      0.80      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=38-mse=0.14270000159740448\n",
      "### Validation result (epoch=38)\n",
      "  Phone level:  MSE=0.143  MAE=0.217  PCC=0.800 \n",
      "   Word level:  MSE=0.104  MAE=0.221  PCC=0.796 \n",
      "    Utt level:  MSE=0.037  MAE=0.148  PCC=0.834 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.14it/s, loss=0.275, loss_phn=0.141, loss_utt=0.0848, loss_word=0.0495, lr=0.000107]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.55      0.31      5524\n",
      "         2.0       0.81      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=39-mse=0.1429000049829483\n",
      "### Validation result (epoch=39)\n",
      "  Phone level:  MSE=0.143  MAE=0.215  PCC=0.799 \n",
      "   Word level:  MSE=0.104  MAE=0.220  PCC=0.796 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.834 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 199.88it/s, loss=0.456, loss_phn=0.266, loss_utt=0.0691, loss_word=0.121, lr=0.000107]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=40-mse=0.14399999380111694\n",
      "### Validation result (epoch=40)\n",
      "  Phone level:  MSE=0.144  MAE=0.211  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.219  PCC=0.794 \n",
      "    Utt level:  MSE=0.039  MAE=0.148  PCC=0.830 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.71it/s, loss=0.127, loss_phn=0.08, loss_utt=0.00688, loss_word=0.0398, lr=0.000107]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=41-mse=0.1436000019311905\n",
      "### Validation result (epoch=41)\n",
      "  Phone level:  MSE=0.144  MAE=0.212  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.220  PCC=0.795 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.31it/s, loss=0.127, loss_phn=0.0749, loss_utt=0.0198, loss_word=0.032, lr=8.59e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.81      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=42-mse=0.14329999685287476\n",
      "### Validation result (epoch=42)\n",
      "  Phone level:  MSE=0.143  MAE=0.212  PCC=0.799 \n",
      "   Word level:  MSE=0.105  MAE=0.220  PCC=0.795 \n",
      "    Utt level:  MSE=0.039  MAE=0.148  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.10it/s, loss=0.378, loss_phn=0.236, loss_utt=0.0241, loss_word=0.117, lr=8.59e-5]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.81      0.55      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=43-mse=0.1437000036239624\n",
      "### Validation result (epoch=43)\n",
      "  Phone level:  MSE=0.144  MAE=0.211  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.218  PCC=0.795 \n",
      "    Utt level:  MSE=0.038  MAE=0.147  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.03it/s, loss=0.107, loss_phn=0.0819, loss_utt=0.012, loss_word=0.0134, lr=8.59e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.55      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=44-mse=0.1437000036239624\n",
      "### Validation result (epoch=44)\n",
      "  Phone level:  MSE=0.144  MAE=0.212  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.217  PCC=0.795 \n",
      "    Utt level:  MSE=0.039  MAE=0.149  PCC=0.831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 201.11it/s, loss=0.231, loss_phn=0.128, loss_utt=0.0145, loss_word=0.0885, lr=6.87e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.80      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=45-mse=0.14390000700950623\n",
      "### Validation result (epoch=45)\n",
      "  Phone level:  MSE=0.144  MAE=0.215  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.222  PCC=0.794 \n",
      "    Utt level:  MSE=0.038  MAE=0.149  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.05it/s, loss=0.193, loss_phn=0.129, loss_utt=0.0357, loss_word=0.0281, lr=6.87e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.82      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=46-mse=0.14399999380111694\n",
      "### Validation result (epoch=46)\n",
      "  Phone level:  MSE=0.144  MAE=0.211  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.218  PCC=0.794 \n",
      "    Utt level:  MSE=0.040  MAE=0.150  PCC=0.829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 199.85it/s, loss=0.195, loss_phn=0.179, loss_utt=0.00413, loss_word=0.0124, lr=6.87e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.54      0.31      5524\n",
      "         2.0       0.81      0.54      0.65     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=47-mse=0.14339999854564667\n",
      "### Validation result (epoch=47)\n",
      "  Phone level:  MSE=0.143  MAE=0.214  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.220  PCC=0.795 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.833 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:16<00:00, 199.18it/s, loss=0.192, loss_phn=0.142, loss_utt=0.0248, loss_word=0.0251, lr=5.5e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.80      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.66      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=48-mse=0.1437000036239624\n",
      "### Validation result (epoch=48)\n",
      "  Phone level:  MSE=0.144  MAE=0.213  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.219  PCC=0.795 \n",
      "    Utt level:  MSE=0.038  MAE=0.148  PCC=0.832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15149/15149 [01:15<00:00, 200.55it/s, loss=0.243, loss_phn=0.136, loss_utt=0.0614, loss_word=0.045, lr=5.5e-5]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91     59975\n",
      "         1.0       0.22      0.53      0.31      5524\n",
      "         2.0       0.80      0.56      0.66     10340\n",
      "\n",
      "    accuracy                           0.81     75839\n",
      "   macro avg       0.66      0.65      0.63     75839\n",
      "weighted avg       0.88      0.81      0.83     75839\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=49-mse=0.14380000531673431\n",
      "### Validation result (epoch=49)\n",
      "  Phone level:  MSE=0.144  MAE=0.213  PCC=0.798 \n",
      "   Word level:  MSE=0.105  MAE=0.219  PCC=0.795 \n",
      "    Utt level:  MSE=0.039  MAE=0.148  PCC=0.829 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 50 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "ckpt_dir = '/data/codes/apa/train/exps/test'\n",
    "\n",
    "cur_lr = lr\n",
    "for epoch in range(num_epoch):\n",
    "    if epoch >= 10 and epoch % 3 == 0:\n",
    "        cur_lr = (4 / 5) * cur_lr \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "                \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gopt_model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            lr=cur_lr,\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        gopt_model=gopt_model, \n",
    "        testloader=testloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n",
    "    global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /data/codes/prep_ps_pykaldi_dev\n",
    "# Training: 100%|██████████| 15329/15329 [01:16<00:00, 199.96it/s, loss=0.297, loss_phn=0.196, loss_utt=0.0429, loss_word=0.0582, lr=0.001]   \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.94      0.81      0.87     62804\n",
    "#          1.0       0.18      0.57      0.27      6015\n",
    "#          2.0       0.76      0.46      0.57     10979\n",
    "\n",
    "#     accuracy                           0.74     79798\n",
    "#    macro avg       0.63      0.61      0.57     79798\n",
    "# weighted avg       0.86      0.74      0.79     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=0-mse=0.188400000333786\n",
    "# ### Validation result (epoch=0)\n",
    "#   Phone level:  MSE=0.188  MAE=0.267  PCC=0.730 \n",
    "#    Word level:  MSE=0.132  MAE=0.273  PCC=0.740 \n",
    "#     Utt level:  MSE=0.050  MAE=0.178  PCC=0.806 \n",
    "# Training: 100%|██████████| 15329/15329 [01:15<00:00, 201.81it/s, loss=0.555, loss_phn=0.327, loss_utt=0.0926, loss_word=0.135, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.81      0.88     62804\n",
    "#          1.0       0.18      0.63      0.28      6015\n",
    "#          2.0       0.80      0.42      0.55     10979\n",
    "\n",
    "#     accuracy                           0.74     79798\n",
    "#    macro avg       0.65      0.62      0.57     79798\n",
    "# weighted avg       0.87      0.74      0.79     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=1-mse=0.17270000278949738\n",
    "# ### Validation result (epoch=1)\n",
    "#   Phone level:  MSE=0.173  MAE=0.271  PCC=0.754 \n",
    "#    Word level:  MSE=0.126  MAE=0.276  PCC=0.758 \n",
    "#     Utt level:  MSE=0.041  MAE=0.162  PCC=0.820 \n",
    "# Training: 100%|██████████| 15329/15329 [01:16<00:00, 200.61it/s, loss=0.242, loss_phn=0.109, loss_utt=0.0581, loss_word=0.0744, lr=0.001]   \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.94      0.88      0.91     62804\n",
    "#          1.0       0.21      0.53      0.30      6015\n",
    "#          2.0       0.82      0.44      0.57     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.62      0.59     79798\n",
    "# weighted avg       0.87      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=2-mse=0.16619999706745148\n",
    "# ### Validation result (epoch=2)\n",
    "#   Phone level:  MSE=0.166  MAE=0.231  PCC=0.768 \n",
    "#    Word level:  MSE=0.125  MAE=0.244  PCC=0.774 \n",
    "#     Utt level:  MSE=0.049  MAE=0.172  PCC=0.822 \n",
    "# Training: 100%|██████████| 15329/15329 [01:16<00:00, 200.61it/s, loss=0.24, loss_phn=0.23, loss_utt=0.00555, loss_word=0.00534, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.85      0.90     62804\n",
    "#          1.0       0.20      0.57      0.30      6015\n",
    "#          2.0       0.80      0.49      0.61     10979\n",
    "\n",
    "#     accuracy                           0.78     79798\n",
    "#    macro avg       0.65      0.64      0.60     79798\n",
    "# weighted avg       0.87      0.78      0.81     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=3-mse=0.16060000658035278\n",
    "# ### Validation result (epoch=3)\n",
    "#   Phone level:  MSE=0.161  MAE=0.242  PCC=0.773 \n",
    "#    Word level:  MSE=0.114  MAE=0.246  PCC=0.778 \n",
    "#     Utt level:  MSE=0.040  MAE=0.156  PCC=0.830 \n",
    "# Training: 100%|██████████| 15329/15329 [01:31<00:00, 168.05it/s, loss=0.402, loss_phn=0.166, loss_utt=0.139, loss_word=0.0974, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.96      0.82      0.89     62804\n",
    "#          1.0       0.20      0.60      0.30      6015\n",
    "#          2.0       0.79      0.53      0.63     10979\n",
    "\n",
    "#     accuracy                           0.77     79798\n",
    "#    macro avg       0.65      0.65      0.61     79798\n",
    "# weighted avg       0.88      0.77      0.81     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=4-mse=0.1574999988079071\n",
    "# ### Validation result (epoch=4)\n",
    "#   Phone level:  MSE=0.157  MAE=0.239  PCC=0.780 \n",
    "#    Word level:  MSE=0.114  MAE=0.242  PCC=0.778 \n",
    "#     Utt level:  MSE=0.038  MAE=0.154  PCC=0.828 \n",
    "# Training: 100%|██████████| 15329/15329 [01:27<00:00, 176.09it/s, loss=0.0829, loss_phn=0.0467, loss_utt=0.017, loss_word=0.0192, lr=0.001]   \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.90     62804\n",
    "#          1.0       0.22      0.56      0.31      6015\n",
    "#          2.0       0.81      0.50      0.62     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.64      0.61     79798\n",
    "# weighted avg       0.87      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=5-mse=0.1527000069618225\n",
    "# ### Validation result (epoch=5)\n",
    "#   Phone level:  MSE=0.153  MAE=0.225  PCC=0.785 \n",
    "#    Word level:  MSE=0.111  MAE=0.232  PCC=0.788 \n",
    "#     Utt level:  MSE=0.037  MAE=0.149  PCC=0.841 \n",
    "# Training: 100%|██████████| 15329/15329 [01:23<00:00, 182.71it/s, loss=0.334, loss_phn=0.154, loss_utt=0.0811, loss_word=0.099, lr=0.001]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.90     62804\n",
    "#          1.0       0.22      0.59      0.32      6015\n",
    "#          2.0       0.81      0.51      0.62     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.65      0.61     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=6-mse=0.1525000035762787\n",
    "# ### Validation result (epoch=6)\n",
    "#   Phone level:  MSE=0.152  MAE=0.224  PCC=0.787 \n",
    "#    Word level:  MSE=0.112  MAE=0.237  PCC=0.784 \n",
    "#     Utt level:  MSE=0.038  MAE=0.154  PCC=0.830 \n",
    "# Training: 100%|██████████| 15329/15329 [02:07<00:00, 120.69it/s, loss=0.161, loss_phn=0.12, loss_utt=0.0158, loss_word=0.0253, lr=0.001]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.96      0.84      0.89     62804\n",
    "#          1.0       0.21      0.60      0.31      6015\n",
    "#          2.0       0.80      0.51      0.63     10979\n",
    "\n",
    "#     accuracy                           0.78     79798\n",
    "#    macro avg       0.65      0.65      0.61     79798\n",
    "# weighted avg       0.88      0.78      0.81     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=7-mse=0.15219999849796295\n",
    "# ### Validation result (epoch=7)\n",
    "#   Phone level:  MSE=0.152  MAE=0.231  PCC=0.787 \n",
    "#    Word level:  MSE=0.112  MAE=0.242  PCC=0.787 \n",
    "#     Utt level:  MSE=0.038  MAE=0.155  PCC=0.842 \n",
    "# Training: 100%|██████████| 15329/15329 [02:08<00:00, 119.03it/s, loss=0.334, loss_phn=0.261, loss_utt=0.0335, loss_word=0.0397, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.59      0.32      6015\n",
    "#          2.0       0.84      0.45      0.59     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.67      0.64      0.60     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=8-mse=0.15129999816417694\n",
    "# ### Validation result (epoch=8)\n",
    "#   Phone level:  MSE=0.151  MAE=0.228  PCC=0.788 \n",
    "#    Word level:  MSE=0.112  MAE=0.229  PCC=0.789 \n",
    "#     Utt level:  MSE=0.037  MAE=0.151  PCC=0.844 \n",
    "# Training: 100%|██████████| 15329/15329 [02:09<00:00, 118.46it/s, loss=0.241, loss_phn=0.181, loss_utt=0.0142, loss_word=0.0458, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.85      0.90     62804\n",
    "#          1.0       0.21      0.61      0.31      6015\n",
    "#          2.0       0.83      0.48      0.61     10979\n",
    "\n",
    "#     accuracy                           0.78     79798\n",
    "#    macro avg       0.67      0.65      0.61     79798\n",
    "# weighted avg       0.88      0.78      0.81     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=9-mse=0.14949999749660492\n",
    "# ### Validation result (epoch=9)\n",
    "#   Phone level:  MSE=0.150  MAE=0.233  PCC=0.790 \n",
    "#    Word level:  MSE=0.111  MAE=0.246  PCC=0.787 \n",
    "#     Utt level:  MSE=0.038  MAE=0.154  PCC=0.840 \n",
    "# Training: 100%|██████████| 15329/15329 [02:08<00:00, 119.00it/s, loss=0.172, loss_phn=0.0973, loss_utt=0.0401, loss_word=0.0346, lr=0.001]   \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.59      0.32      6015\n",
    "#          2.0       0.84      0.48      0.61     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.67      0.64      0.61     79798\n",
    "# weighted avg       0.88      0.80      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=10-mse=0.14650000631809235\n",
    "# ### Validation result (epoch=10)\n",
    "#   Phone level:  MSE=0.146  MAE=0.224  PCC=0.796 \n",
    "#    Word level:  MSE=0.109  MAE=0.227  PCC=0.793 \n",
    "#     Utt level:  MSE=0.037  MAE=0.150  PCC=0.839 \n",
    "# Training: 100%|██████████| 15329/15329 [02:08<00:00, 119.33it/s, loss=0.242, loss_phn=0.143, loss_utt=0.0433, loss_word=0.0551, lr=0.001]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.90     62804\n",
    "#          1.0       0.22      0.58      0.32      6015\n",
    "#          2.0       0.81      0.52      0.63     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.65      0.62     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=11-mse=0.147599995136261\n",
    "# ### Validation result (epoch=11)\n",
    "#   Phone level:  MSE=0.148  MAE=0.226  PCC=0.793 \n",
    "#    Word level:  MSE=0.108  MAE=0.235  PCC=0.791 \n",
    "#     Utt level:  MSE=0.035  MAE=0.147  PCC=0.843 \n",
    "# Training: 100%|██████████| 15329/15329 [02:09<00:00, 118.09it/s, loss=0.192, loss_phn=0.134, loss_utt=0.0106, loss_word=0.0482, lr=0.0008]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.90     62804\n",
    "#          1.0       0.21      0.59      0.31      6015\n",
    "#          2.0       0.82      0.50      0.62     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.65      0.61     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=12-mse=0.1467999964952469\n",
    "# ### Validation result (epoch=12)\n",
    "#   Phone level:  MSE=0.147  MAE=0.225  PCC=0.794 \n",
    "#    Word level:  MSE=0.107  MAE=0.230  PCC=0.794 \n",
    "#     Utt level:  MSE=0.036  MAE=0.146  PCC=0.842 \n",
    "# Training: 100%|██████████| 15329/15329 [01:20<00:00, 191.55it/s, loss=0.159, loss_phn=0.117, loss_utt=0.013, loss_word=0.0296, lr=0.0008]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.88      0.91     62804\n",
    "#          1.0       0.22      0.55      0.32      6015\n",
    "#          2.0       0.81      0.50      0.62     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.66      0.64      0.62     79798\n",
    "# weighted avg       0.87      0.80      0.83     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=13-mse=0.14749999344348907\n",
    "# ### Validation result (epoch=13)\n",
    "#   Phone level:  MSE=0.148  MAE=0.214  PCC=0.795 \n",
    "#    Word level:  MSE=0.108  MAE=0.225  PCC=0.793 \n",
    "#     Utt level:  MSE=0.035  MAE=0.147  PCC=0.844 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.76it/s, loss=0.552, loss_phn=0.248, loss_utt=0.129, loss_word=0.175, lr=0.0008]      \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.58      0.32      6015\n",
    "#          2.0       0.82      0.51      0.63     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.66      0.65      0.62     79798\n",
    "# weighted avg       0.88      0.80      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=14-mse=0.14560000598430634\n",
    "# ### Validation result (epoch=14)\n",
    "#   Phone level:  MSE=0.146  MAE=0.219  PCC=0.797 \n",
    "#    Word level:  MSE=0.107  MAE=0.232  PCC=0.795 \n",
    "#     Utt level:  MSE=0.036  MAE=0.150  PCC=0.840 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.57it/s, loss=0.435, loss_phn=0.279, loss_utt=0.0316, loss_word=0.124, lr=0.00064]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.91     62804\n",
    "#          1.0       0.22      0.58      0.32      6015\n",
    "#          2.0       0.82      0.53      0.64     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.66      0.66      0.62     79798\n",
    "# weighted avg       0.88      0.80      0.83     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=15-mse=0.14309999346733093\n",
    "# ### Validation result (epoch=15)\n",
    "#   Phone level:  MSE=0.143  MAE=0.217  PCC=0.801 \n",
    "#    Word level:  MSE=0.104  MAE=0.228  PCC=0.800 \n",
    "#     Utt level:  MSE=0.034  MAE=0.143  PCC=0.850 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.73it/s, loss=0.657, loss_phn=0.295, loss_utt=0.14, loss_word=0.221, lr=0.00064]       \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.58      0.32      6015\n",
    "#          2.0       0.83      0.51      0.63     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.67      0.65      0.62     79798\n",
    "# weighted avg       0.88      0.80      0.83     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=16-mse=0.14429999887943268\n",
    "# ### Validation result (epoch=16)\n",
    "#   Phone level:  MSE=0.144  MAE=0.223  PCC=0.798 \n",
    "#    Word level:  MSE=0.104  MAE=0.226  PCC=0.799 \n",
    "#     Utt level:  MSE=0.035  MAE=0.144  PCC=0.849 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 198.20it/s, loss=0.406, loss_phn=0.141, loss_utt=0.0962, loss_word=0.169, lr=0.00064]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.91     62804\n",
    "#          1.0       0.22      0.59      0.32      6015\n",
    "#          2.0       0.82      0.52      0.63     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.66      0.66      0.62     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=17-mse=0.14380000531673431\n",
    "# ### Validation result (epoch=17)\n",
    "#   Phone level:  MSE=0.144  MAE=0.223  PCC=0.799 \n",
    "#    Word level:  MSE=0.105  MAE=0.229  PCC=0.797 \n",
    "#     Utt level:  MSE=0.036  MAE=0.145  PCC=0.842 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.87it/s, loss=0.218, loss_phn=0.143, loss_utt=0.0215, loss_word=0.0538, lr=0.000512]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.86      0.90     62804\n",
    "#          1.0       0.22      0.61      0.32      6015\n",
    "#          2.0       0.83      0.50      0.63     10979\n",
    "\n",
    "#     accuracy                           0.79     79798\n",
    "#    macro avg       0.67      0.66      0.62     79798\n",
    "# weighted avg       0.88      0.79      0.82     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=18-mse=0.14419999718666077\n",
    "# ### Validation result (epoch=18)\n",
    "#   Phone level:  MSE=0.144  MAE=0.224  PCC=0.799 \n",
    "#    Word level:  MSE=0.105  MAE=0.223  PCC=0.800 \n",
    "#     Utt level:  MSE=0.037  MAE=0.147  PCC=0.842 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.11it/s, loss=0.276, loss_phn=0.147, loss_utt=0.0119, loss_word=0.117, lr=0.000512]     \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.57      0.32      6015\n",
    "#          2.0       0.83      0.50      0.63     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.67      0.65      0.62     79798\n",
    "# weighted avg       0.88      0.80      0.83     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=19-mse=0.1446000039577484\n",
    "# ### Validation result (epoch=19)\n",
    "#   Phone level:  MSE=0.145  MAE=0.218  PCC=0.798 \n",
    "#    Word level:  MSE=0.104  MAE=0.219  PCC=0.800 \n",
    "#     Utt level:  MSE=0.036  MAE=0.145  PCC=0.843 \n",
    "# Training: 100%|██████████| 15329/15329 [01:17<00:00, 197.46it/s, loss=0.232, loss_phn=0.0536, loss_utt=0.133, loss_word=0.0458, lr=0.000512]    \n",
    "# ### F1 Score: \n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.87      0.91     62804\n",
    "#          1.0       0.22      0.58      0.32      6015\n",
    "#          2.0       0.82      0.51      0.63     10979\n",
    "\n",
    "#     accuracy                           0.80     79798\n",
    "#    macro avg       0.67      0.65      0.62     79798\n",
    "# weighted avg       0.88      0.80      0.83     79798\n",
    "\n",
    "# Save state dict and result to /data/codes/apa/train/exps/scores/ckpts-eph=20-mse=0.1444000005722046\n",
    "# ### Validation result (epoch=20)\n",
    "#   Phone level:  MSE=0.144  MAE=0.216  PCC=0.799 \n",
    "#    Word level:  MSE=0.105  MAE=0.227  PCC=0.797 \n",
    "#     Utt level:  MSE=0.036  MAE=0.147  PCC=0.842 \n",
    "# Training:  88%|████████▊ | 13439/15329 [01:09<00:09, 199.14it/s, loss=0.34, loss_phn=0.175, loss_utt=0.0896, loss_word=0.0752, lr=0.00041]     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
