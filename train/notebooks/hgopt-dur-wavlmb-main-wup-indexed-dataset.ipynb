{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "%cd /data/codes/apa/train/\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from src.utils.train import (\n",
    "    load_data,\n",
    "    to_device,\n",
    "    validate\n",
    ")\n",
    "\n",
    "from src.dataset import PrepDataset\n",
    "from src.model import PrepModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '/data/codes/apa/train/exp/dev'\n",
    "train_dir = \"/data/codes/apa/train/data/feats/train/train-data-type-12/\"\n",
    "test_dir = \"/data/codes/apa/train/data/feats/train/train-data-type-12/\"\n",
    "\n",
    "ids, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(train_dir)\n",
    "\n",
    "trainset = PrepDataset(\n",
    "    ids=ids,\n",
    "    phone_ids=phone_ids,\n",
    "    word_ids=word_ids,\n",
    "    durations=durations,\n",
    "    gops=gops,\n",
    "    phone_scores=phone_scores,\n",
    "    relative_positions=relative_positions,\n",
    "    sentence_scores=sentence_scores,\n",
    "    wavlm_features_path=wavlm_features_path,\n",
    "    word_scores=word_scores\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=8, \n",
    "    num_workers=1,\n",
    "    shuffle=True, \n",
    "    drop_last=False, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "ids, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(test_dir)\n",
    "    \n",
    "testset = PrepDataset(\n",
    "    ids=ids,\n",
    "    phone_ids=phone_ids,\n",
    "    word_ids=word_ids,\n",
    "    durations=durations,\n",
    "    gops=gops,\n",
    "    phone_scores=phone_scores,\n",
    "    relative_positions=relative_positions,\n",
    "    sentence_scores=sentence_scores,\n",
    "    wavlm_features_path=wavlm_features_path,\n",
    "    word_scores=word_scores\n",
    ")\n",
    "\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    num_workers=1,\n",
    "    batch_size=64, \n",
    "    shuffle=False, \n",
    "    drop_last=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=855\n",
    "num_phone=44\n",
    "max_length=128\n",
    "dropout=0.1\n",
    "\n",
    "lr=1e-3\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = PrepModel(\n",
    "    embed_dim=embed_dim, \n",
    "    num_heads=num_heads, \n",
    "    depth=depth, \n",
    "    input_dim=input_dim, \n",
    "    max_length=max_length, \n",
    "    num_phone=num_phone, \n",
    "    dropout=dropout).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 50 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "\n",
    "cur_lr = lr\n",
    "for epoch in range(num_epoch):\n",
    "    if epoch >= 10 and epoch % 3 == 0:\n",
    "        cur_lr = (4 / 5) * cur_lr \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids, features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "                \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gopt_model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            lr=cur_lr,\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        optimizer=optimizer,\n",
    "        gopt_model=gopt_model, \n",
    "        testloader=testloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir,\n",
    "        device=device)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n",
    "    global_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
