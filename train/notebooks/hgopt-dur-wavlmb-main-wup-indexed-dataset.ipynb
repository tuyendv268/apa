{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/apa/train\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/apa/train/\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from src.dataset import PrepDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    if RED_YELLOW is not None:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":2}\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "    else:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":1}\n",
    "        RED_YELLOW = 30/50\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_data(data_dir):\n",
    "    phone_ids = np.load(f'{data_dir}/phone_ids.npy')\n",
    "    word_ids = np.load(f'{data_dir}/word_ids.npy')\n",
    "    \n",
    "    phone_scores = np.load(f'{data_dir}/phone_scores.npy')\n",
    "    word_scores = np.load(f'{data_dir}/word_scores.npy')\n",
    "    sentence_scores = np.load(f'{data_dir}/sentence_scores.npy')\n",
    "\n",
    "    durations = np.load(f'{data_dir}/duration.npy')\n",
    "    gops = np.load(f'{data_dir}/gop.npy')\n",
    "    # wavlm_features = np.load(f'{data_dir}/wavlm_features.npy')\n",
    "    wavlm_features_path = f'{data_dir}/wavlm_features'\n",
    "\n",
    "    relative_positions = np.load(f'{data_dir}/relative_positions.npy')\n",
    "\n",
    "    return phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, relative_positions, wavlm_features_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.indexed_dataset import IndexedDataset\n",
    "import torch\n",
    "\n",
    "class PrepDataset(Dataset):\n",
    "    def __init__(self, phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "            sentence_scores, durations, gops, relative_positions, wavlm_features_path):\n",
    "        self.phone_ids = phone_ids\n",
    "        self.word_ids = word_ids\n",
    "\n",
    "        self.phone_scores = phone_scores\n",
    "        self.word_scores = word_scores\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "        self.gops = gops\n",
    "        self.durations = durations\n",
    "        self.wavlm_features = IndexedDataset(wavlm_features_path)\n",
    "        self.relative_positions = relative_positions\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.phone_ids.shape[0]\n",
    "    \n",
    "    def parse_data(self, phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "            sentence_scores, durations, gops, wavlm_features, relative_positions):\n",
    "        \n",
    "        phone_ids = torch.tensor(phone_ids)\n",
    "        word_ids = torch.tensor(word_ids)\n",
    "\n",
    "        phone_scores = torch.tensor(phone_scores).float().clone()\n",
    "        word_scores = torch.tensor(word_scores).float().clone()\n",
    "        sentence_scores = torch.tensor(sentence_scores).float().clone()\n",
    "\n",
    "        phone_scores[phone_scores != -1] /= 50\n",
    "        word_scores[word_scores != -1] /= 50\n",
    "        sentence_scores /= 50\n",
    "\n",
    "        durations = torch.tensor(durations)\n",
    "        gops = torch.tensor(gops)\n",
    "        wavlm_features = torch.tensor(wavlm_features)\n",
    "        relative_positions = torch.tensor(relative_positions)\n",
    "\n",
    "        features = torch.concat([gops, durations.unsqueeze(-1), wavlm_features], dim=-1)        \n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"phone_ids\": phone_ids,\n",
    "            \"word_ids\": word_ids,\n",
    "            \"phone_scores\":phone_scores,\n",
    "            \"word_scores\":word_scores,\n",
    "            \"sentence_scores\":sentence_scores,\n",
    "            \"relative_positions\": relative_positions\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phone_ids = self.phone_ids[index]\n",
    "        word_ids = self.word_ids[index]\n",
    "\n",
    "        phone_scores = self.phone_scores[index]\n",
    "        word_scores = self.word_scores[index]\n",
    "        sentence_scores = self.sentence_scores[index]\n",
    "\n",
    "        gops = self.gops[index]\n",
    "        durations = self.durations[index]\n",
    "        wavlm_features = self.wavlm_features[index]\n",
    "        relative_positions = self.relative_positions[index]\n",
    "\n",
    "        return self.parse_data(\n",
    "            phone_ids=phone_ids,\n",
    "            word_ids=word_ids,\n",
    "            phone_scores=phone_scores,\n",
    "            word_scores=word_scores,\n",
    "            sentence_scores=sentence_scores,\n",
    "            gops=gops,\n",
    "            durations=durations,\n",
    "            wavlm_features=wavlm_features,\n",
    "            relative_positions=relative_positions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "ckpt_dir = '/data/codes/apa/train/exps/test'\n",
    "train_dir = \"/data/codes/apa/train/exps/features/train/merged\"\n",
    "test_dir = \"/data/codes/apa/train/exps/features/test/out-long\"\n",
    "\n",
    "phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(train_dir)\n",
    "trainset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, relative_positions, wavlm_features_path)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=False, pin_memory=True, num_workers=1)\n",
    "\n",
    "phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(test_dir)\n",
    "    \n",
    "testset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, relative_positions, wavlm_features_path)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import PrepModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=853\n",
    "num_phone=43\n",
    "max_length=128\n",
    "\n",
    "lr=1e-3\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = PrepModel(\n",
    "    embed_dim=embed_dim, num_heads=num_heads, \n",
    "    depth=depth, input_dim=input_dim, \n",
    "    max_length=max_length, num_phone=num_phone, dropout=0.1).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/data/codes/apa/train/exps/test/ckpts-eph=10-mse=0.16089999675750732/model.pt\")\n",
    "gopt_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(predict, target):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(predict.shape[0]):\n",
    "        for j in range(predict.shape[1]):\n",
    "            if target[i, j] >= 0:\n",
    "                preds.append(predict[i, j])\n",
    "                targs.append(target[i, j])\n",
    "    targs = np.array(targs)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    mse = np.mean((targs - preds) ** 2)\n",
    "    mae = np.mean(np.abs(targs - preds))\n",
    "    corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    return mse, mae, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_wrd(predict, target, word_id):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(target.shape[0]):\n",
    "        prev_w_id, start_id = 0, 0\n",
    "        # for each token\n",
    "        for j in range(target.shape[1]):\n",
    "            cur_w_id = word_id[i, j].int()\n",
    "            # if a new word\n",
    "            if cur_w_id != prev_w_id:\n",
    "                # average each phone belongs to the word\n",
    "                preds.append(np.mean(predict[i, start_id: j].numpy(), axis=0))\n",
    "                targs.append(np.mean(target[i, start_id: j].numpy(), axis=0))\n",
    "\n",
    "                if cur_w_id == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    prev_w_id = cur_w_id\n",
    "                    start_id = j\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    targs = np.array(targs).round(2)\n",
    "\n",
    "    word_mse = np.mean((preds - targs) ** 2)\n",
    "    wrd_mae = np.mean(np.abs(preds - targs))\n",
    "    word_corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    \n",
    "    return word_mse, wrd_mae, word_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_utt(predict, target):\n",
    "    utt_mse = np.mean(((predict[:, 0] - target[:, 0]) ** 2).numpy())\n",
    "    utt_mae = np.mean((np.abs(predict[:, 0] - target[:, 0])).numpy())\n",
    "    \n",
    "    utt_corr = np.corrcoef(predict[:, 0], target[:, 0])[0, 1]\n",
    "    return utt_mse, utt_mae, utt_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch, device):\n",
    "    features = batch[\"features\"].to(device)\n",
    "    phone_ids = batch[\"phone_ids\"].to(device)\n",
    "    relative_positions = batch[\"relative_positions\"].to(device)\n",
    "    word_ids = batch[\"word_ids\"]\n",
    "    \n",
    "    phone_labels = batch[\"phone_scores\"].to(device)\n",
    "    word_labels = batch[\"word_scores\"].to(device)\n",
    "    utterance_labels = batch[\"sentence_scores\"].to(device)\n",
    "\n",
    "    return features, phone_ids, word_ids, relative_positions, phone_labels, word_labels, utterance_labels\n",
    "\n",
    "def to_cpu(preds, labels):\n",
    "    preds = preds.detach().cpu().squeeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    \n",
    "    return label[index], pred[index]\n",
    "\n",
    "def save_confusion_matrix_figure(\n",
    "        fig_path, pred_path, label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    \n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(\n",
    "        torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    predicted = convert_score_to_color(\n",
    "        torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    if RED_YELLOW is not None:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    else:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"CORRECT\", \"INCORRECT\"])\n",
    "\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.savefig(fig_path) \n",
    "    plt.close()\n",
    "\n",
    "def save(epoch, output_dir, model, optimizer, phone_desicion_result, \\\n",
    "    phone_predicts, phone_labels, word_predicts, word_labels, utterance_predicts, utterance_labels):\n",
    "    \n",
    "    model_path = f'{output_dir}/model.pt'\n",
    "    optimizer_path = f'{output_dir}/optimizer.pt'\n",
    "    phone_desicion_result_path = f'{output_dir}/phone_result'\n",
    "\n",
    "    phone_predict_path = f'{output_dir}/phn_pred.npy'\n",
    "    phone_label_path = f'{output_dir}/phn_label.npy'\n",
    "    word_predict_path = f'{output_dir}/wrd_pred.npy'\n",
    "    word_label_path = f'{output_dir}/wrd_label.npy'\n",
    "    utterance_predict_path = f'{output_dir}/utt_pred.npy'\n",
    "    utterance_label_path = f'{output_dir}/utt_label.npy'\n",
    "\n",
    "    three_class_fig_path = f'{output_dir}/confusion_matrix_three_class.png'\n",
    "    two_class_fig_path = f'{output_dir}/confusion_matrix_two_class.png'\n",
    "\n",
    "    with open(phone_desicion_result_path, \"w\") as f:\n",
    "        f.write(phone_desicion_result)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    np.save(phone_predict_path, phone_predicts)\n",
    "    np.save(phone_label_path, phone_labels)\n",
    "    np.save(word_predict_path, word_predicts)\n",
    "    np.save(word_label_path, word_labels)\n",
    "    np.save(utterance_predict_path, utterance_predicts)\n",
    "    np.save(utterance_label_path, utterance_labels)\n",
    "    save_confusion_matrix_figure(three_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=40/50)\n",
    "    save_confusion_matrix_figure(two_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=None)\n",
    "\n",
    "    print(f'Save state dict and result to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(epoch, gopt_model, testloader, best_mse, ckpt_dir):\n",
    "    gopt_model.eval()\n",
    "    A_phn, A_phn_target = [], []\n",
    "    A_utt, A_utt_target = [], []\n",
    "    A_wrd, A_wrd_target, A_wrd_id = [], [], []\n",
    "\n",
    "    for batch in testloader:\n",
    "        features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "        \n",
    "        phone_preds, phone_labels = to_cpu(phone_preds, phone_labels)\n",
    "        word_preds, word_labels = to_cpu(word_preds, word_labels)\n",
    "        utterance_preds, utterance_labels = to_cpu(utterance_preds, utterance_labels)\n",
    "        \n",
    "        A_phn.append(phone_preds), A_phn_target.append(phone_labels)\n",
    "        A_utt.append(utterance_preds), A_utt_target.append(utterance_labels)\n",
    "        A_wrd.append(word_preds), A_wrd_target.append(word_labels), A_wrd_id.append(word_ids)\n",
    "    \n",
    "    # phone level\n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    decision_result = calculate_phone_decision_result(A_phn, A_phn_target)\n",
    "\n",
    "    # word level\n",
    "    A_word, A_word_target, A_word_id = torch.vstack(A_wrd), torch.vstack(A_wrd_target), torch.vstack(A_wrd_id) \n",
    "\n",
    "    # utterance level\n",
    "    A_utt, A_utt_target = torch.vstack(A_utt), torch.vstack(A_utt_target)\n",
    "\n",
    "    # valid_token_mse, mae, corr\n",
    "    phn_mse, phn_mae, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    word_mse, wrd_mae, word_corr = valid_wrd(A_word, A_word_target, A_word_id)\n",
    "    utt_mse, utt_mae, utt_corr = valid_utt(A_utt, A_utt_target)\n",
    "\n",
    "    if phn_mse < best_mse:\n",
    "        best_mse = phn_mse\n",
    "    ckpt_dir = f'{ckpt_dir}/ckpts-eph={epoch}-mse={round(phn_mse, 4)}'\n",
    "    os.makedirs(ckpt_dir)\n",
    "    \n",
    "    save(\n",
    "        epoch=epoch,\n",
    "        output_dir=ckpt_dir, \n",
    "        model=gopt_model, \n",
    "        optimizer=optimizer, \n",
    "        phone_desicion_result=decision_result,\n",
    "        phone_predicts=A_phn.numpy(), \n",
    "        phone_labels=A_phn_target.numpy(), \n",
    "        word_predicts=A_word.numpy(), \n",
    "        word_labels=A_word_target.numpy(), \n",
    "        utterance_predicts=A_utt.numpy(), \n",
    "        utterance_labels=A_utt_target.numpy()\n",
    "    )\n",
    "    \n",
    "    with open(f'{ckpt_dir}/pcc', \"w\") as f:\n",
    "        f.write(\"Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(phn_mse, phn_mae, phn_corr))\n",
    "        f.write(\"Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(word_mse, wrd_mae, word_corr))\n",
    "        f.write(\"Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \\n\".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    print(f\"### Validation result (epoch={epoch})\")\n",
    "    print(\"  Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(phn_mse, phn_mae, phn_corr))\n",
    "    print(\"   Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(word_mse, wrd_mae, word_corr))\n",
    "    print(\"    Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    return {\n",
    "        \"phn_mse\": phn_mse, \n",
    "        \"phn_mae\": phn_mae,\n",
    "        \"phn_corr\": phn_corr,\n",
    "        \"word_mse\": word_mse,\n",
    "        \"wrd_mae\": wrd_mae,\n",
    "        \"word_corr\": word_corr,\n",
    "        \"utt_mse\": utt_mse,\n",
    "        \"utt_mae\": utt_mae,\n",
    "        \"utt_corr\": utt_corr,\n",
    "        \"best_mse\": best_mse\n",
    "    }\n",
    "\n",
    "def calculate_phone_decision_result(A_phn, A_phn_target):\n",
    "    indices = A_phn_target != -1\n",
    "    _label = A_phn_target[indices].clone()\n",
    "    _pred = A_phn[indices].clone()\n",
    "\n",
    "    converted_pred = convert_score_to_color(_pred).view(-1)\n",
    "    converted_label = convert_score_to_color(_label).view(-1)\n",
    "\n",
    "    result = classification_report(y_true=converted_label, y_pred=converted_pred)\n",
    "    print(\"### F1 Score: \\n\", result)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "    # loss_utt = torch.tensor(0)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:34<00:00, 220.42it/s, loss=0.318, loss_phn=0.27, loss_utt=0.03, loss_word=0.0181, lr=0.001]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88     61683\n",
      "         1.0       0.20      0.57      0.29      6508\n",
      "         2.0       0.81      0.42      0.56     12113\n",
      "\n",
      "    accuracy                           0.75     80304\n",
      "   macro avg       0.65      0.61      0.58     80304\n",
      "weighted avg       0.86      0.75      0.78     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=0-mse=0.19220000505447388\n",
      "### Validation result (epoch=0)\n",
      "  Phone level:  MSE=0.192  MAE=0.271  PCC=0.742 \n",
      "   Word level:  MSE=0.137  MAE=0.271  PCC=0.735 \n",
      "    Utt level:  MSE=0.050  MAE=0.177  PCC=0.784 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:38<00:00, 213.79it/s, loss=1.04, loss_phn=0.361, loss_utt=0.304, loss_word=0.377, lr=0.001]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90     61683\n",
      "         1.0       0.21      0.53      0.30      6508\n",
      "         2.0       0.82      0.42      0.56     12113\n",
      "\n",
      "    accuracy                           0.77     80304\n",
      "   macro avg       0.65      0.61      0.58     80304\n",
      "weighted avg       0.85      0.77      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=1-mse=0.1873999983072281\n",
      "### Validation result (epoch=1)\n",
      "  Phone level:  MSE=0.187  MAE=0.250  PCC=0.754 \n",
      "   Word level:  MSE=0.136  MAE=0.262  PCC=0.752 \n",
      "    Utt level:  MSE=0.052  MAE=0.177  PCC=0.807 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:39<00:00, 213.19it/s, loss=0.266, loss_phn=0.133, loss_utt=0.018, loss_word=0.115, lr=0.001]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88     61683\n",
      "         1.0       0.21      0.58      0.30      6508\n",
      "         2.0       0.80      0.51      0.62     12113\n",
      "\n",
      "    accuracy                           0.76     80304\n",
      "   macro avg       0.65      0.64      0.60     80304\n",
      "weighted avg       0.86      0.76      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=2-mse=0.17430000007152557\n",
      "### Validation result (epoch=2)\n",
      "  Phone level:  MSE=0.174  MAE=0.251  PCC=0.771 \n",
      "   Word level:  MSE=0.124  MAE=0.260  PCC=0.763 \n",
      "    Utt level:  MSE=0.041  MAE=0.160  PCC=0.829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:39<00:00, 212.45it/s, loss=0.193, loss_phn=0.146, loss_utt=0.0186, loss_word=0.0287, lr=0.001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88     61683\n",
      "         1.0       0.20      0.61      0.30      6508\n",
      "         2.0       0.82      0.48      0.61     12113\n",
      "\n",
      "    accuracy                           0.75     80304\n",
      "   macro avg       0.65      0.64      0.60     80304\n",
      "weighted avg       0.87      0.75      0.79     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=3-mse=0.17110000550746918\n",
      "### Validation result (epoch=3)\n",
      "  Phone level:  MSE=0.171  MAE=0.261  PCC=0.776 \n",
      "   Word level:  MSE=0.123  MAE=0.255  PCC=0.766 \n",
      "    Utt level:  MSE=0.040  MAE=0.159  PCC=0.831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:40<00:00, 212.16it/s, loss=0.0796, loss_phn=0.0467, loss_utt=0.00585, loss_word=0.0271, lr=0.001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90     61683\n",
      "         1.0       0.22      0.54      0.31      6508\n",
      "         2.0       0.82      0.48      0.61     12113\n",
      "\n",
      "    accuracy                           0.78     80304\n",
      "   macro avg       0.66      0.63      0.60     80304\n",
      "weighted avg       0.86      0.78      0.81     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=4-mse=0.16910000145435333\n",
      "### Validation result (epoch=4)\n",
      "  Phone level:  MSE=0.169  MAE=0.237  PCC=0.780 \n",
      "   Word level:  MSE=0.128  MAE=0.250  PCC=0.772 \n",
      "    Utt level:  MSE=0.045  MAE=0.166  PCC=0.829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:40<00:00, 211.63it/s, loss=0.141, loss_phn=0.0969, loss_utt=0.0192, loss_word=0.0246, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     61683\n",
      "         1.0       0.21      0.58      0.31      6508\n",
      "         2.0       0.83      0.46      0.59     12113\n",
      "\n",
      "    accuracy                           0.77     80304\n",
      "   macro avg       0.66      0.63      0.60     80304\n",
      "weighted avg       0.87      0.77      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=5-mse=0.16899999976158142\n",
      "### Validation result (epoch=5)\n",
      "  Phone level:  MSE=0.169  MAE=0.243  PCC=0.779 \n",
      "   Word level:  MSE=0.121  MAE=0.244  PCC=0.773 \n",
      "    Utt level:  MSE=0.045  MAE=0.165  PCC=0.840 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:40<00:00, 211.58it/s, loss=0.401, loss_phn=0.333, loss_utt=0.04, loss_word=0.0283, lr=0.001]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90     61683\n",
      "         1.0       0.22      0.56      0.32      6508\n",
      "         2.0       0.82      0.50      0.62     12113\n",
      "\n",
      "    accuracy                           0.78     80304\n",
      "   macro avg       0.66      0.64      0.61     80304\n",
      "weighted avg       0.86      0.78      0.81     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=6-mse=0.16410000622272491\n",
      "### Validation result (epoch=6)\n",
      "  Phone level:  MSE=0.164  MAE=0.236  PCC=0.786 \n",
      "   Word level:  MSE=0.116  MAE=0.243  PCC=0.782 \n",
      "    Utt level:  MSE=0.041  MAE=0.159  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:40<00:00, 211.42it/s, loss=0.15, loss_phn=0.0951, loss_utt=0.00779, loss_word=0.0468, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89     61683\n",
      "         1.0       0.21      0.60      0.31      6508\n",
      "         2.0       0.82      0.50      0.62     12113\n",
      "\n",
      "    accuracy                           0.77     80304\n",
      "   macro avg       0.66      0.64      0.61     80304\n",
      "weighted avg       0.87      0.77      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=7-mse=0.1607999950647354\n",
      "### Validation result (epoch=7)\n",
      "  Phone level:  MSE=0.161  MAE=0.241  PCC=0.790 \n",
      "   Word level:  MSE=0.117  MAE=0.250  PCC=0.779 \n",
      "    Utt level:  MSE=0.035  MAE=0.148  PCC=0.855 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:41<00:00, 210.83it/s, loss=0.461, loss_phn=0.191, loss_utt=0.115, loss_word=0.156, lr=0.001]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90     61683\n",
      "         1.0       0.22      0.58      0.32      6508\n",
      "         2.0       0.85      0.44      0.58     12113\n",
      "\n",
      "    accuracy                           0.78     80304\n",
      "   macro avg       0.67      0.63      0.60     80304\n",
      "weighted avg       0.87      0.78      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=8-mse=0.16609999537467957\n",
      "### Validation result (epoch=8)\n",
      "  Phone level:  MSE=0.166  MAE=0.244  PCC=0.784 \n",
      "   Word level:  MSE=0.121  MAE=0.248  PCC=0.782 \n",
      "    Utt level:  MSE=0.044  MAE=0.165  PCC=0.841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:40<00:00, 211.21it/s, loss=0.0746, loss_phn=0.0379, loss_utt=0.0179, loss_word=0.0187, lr=0.001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89     61683\n",
      "         1.0       0.21      0.59      0.31      6508\n",
      "         2.0       0.81      0.52      0.64     12113\n",
      "\n",
      "    accuracy                           0.77     80304\n",
      "   macro avg       0.66      0.65      0.61     80304\n",
      "weighted avg       0.87      0.77      0.80     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=9-mse=0.16179999709129333\n",
      "### Validation result (epoch=9)\n",
      "  Phone level:  MSE=0.162  MAE=0.239  PCC=0.789 \n",
      "   Word level:  MSE=0.114  MAE=0.241  PCC=0.787 \n",
      "    Utt level:  MSE=0.034  MAE=0.144  PCC=0.858 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:52<00:00, 197.02it/s, loss=0.246, loss_phn=0.177, loss_utt=0.00494, loss_word=0.0642, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90     61683\n",
      "         1.0       0.22      0.58      0.32      6508\n",
      "         2.0       0.84      0.47      0.61     12113\n",
      "\n",
      "    accuracy                           0.78     80304\n",
      "   macro avg       0.67      0.64      0.61     80304\n",
      "weighted avg       0.87      0.78      0.81     80304\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exps/test/ckpts-eph=10-mse=0.16089999675750732\n",
      "### Validation result (epoch=10)\n",
      "  Phone level:  MSE=0.161  MAE=0.237  PCC=0.791 \n",
      "   Word level:  MSE=0.114  MAE=0.239  PCC=0.785 \n",
      "    Utt level:  MSE=0.036  MAE=0.147  PCC=0.854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 33968/33968 [02:44<00:00, 206.93it/s, loss=0.864, loss_phn=0.74, loss_utt=0.0514, loss_word=0.0723, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.88     61683\n",
      "         1.0       0.21      0.61      0.31      6508\n",
      "         2.0       0.82      0.51      0.63     12113\n",
      "\n",
      "    accuracy                           0.76     80304\n",
      "   macro avg       0.66      0.65      0.61     80304\n",
      "weighted avg       0.87      0.76      0.80     80304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 50 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "\n",
    "cur_lr = lr\n",
    "for epoch in range(num_epoch):\n",
    "    if epoch >= 10 and epoch % 3 == 0:\n",
    "        cur_lr = (4 / 5) * cur_lr \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "                \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gopt_model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            lr=cur_lr,\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        gopt_model=gopt_model, \n",
    "        testloader=testloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n",
    "    global_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
