{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/apa/train\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "%cd /data/codes/apa/train/\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from src.dataset import PrepDataset\n",
    "from src.model import PrepModel\n",
    "from src.utils.train import (\n",
    "    load_data,\n",
    "    convert_score_to_color,\n",
    "    to_device,\n",
    "    valid_phn,\n",
    "    valid_utt,\n",
    "    valid_wrd,\n",
    "    to_cpu,\n",
    "    load_pred_and_label,\n",
    "    save_confusion_matrix_figure,\n",
    "    validate,\n",
    "    save\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '/data/codes/apa/train/exp/ckpts/dev'\n",
    "in_dir = \"/data/codes/apa/train/data/feats/train/train-data-type-12\"\n",
    "out_dir = f'{in_dir}-filtered'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81277/81277 [00:09<00:00, 8426.49it/s]\n"
     ]
    }
   ],
   "source": [
    "ids, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(in_dir)\n",
    "\n",
    "dataset = PrepDataset(\n",
    "    ids=ids, \n",
    "    phone_ids=phone_ids, \n",
    "    word_ids=word_ids, \n",
    "    phone_scores=phone_scores, \n",
    "    word_scores=word_scores,\n",
    "    sentence_scores=sentence_scores, \n",
    "    durations=durations, \n",
    "    gops=gops, \n",
    "    relative_positions=relative_positions, \n",
    "    wavlm_features_path=wavlm_features_path)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=8, \n",
    "    num_workers=1,\n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    pin_memory=True, \n",
    ")\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    batch = dataset[i]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=855\n",
    "num_phone=44\n",
    "max_length=128\n",
    "\n",
    "lr=1e-3\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = PrepModel(\n",
    "    embed_dim=embed_dim, num_heads=num_heads, \n",
    "    depth=depth, input_dim=input_dim, \n",
    "    max_length=max_length, num_phone=num_phone, dropout=0.1).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:48<00:00, 207.76it/s, loss=0.299, loss_phn=0.201, loss_utt=0.0616, loss_word=0.0356, lr=0.001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87    462840\n",
      "         1.0       0.18      0.54      0.27     51045\n",
      "         2.0       0.79      0.36      0.49    100203\n",
      "\n",
      "    accuracy                           0.72    614088\n",
      "   macro avg       0.63      0.57      0.54    614088\n",
      "weighted avg       0.84      0.72      0.76    614088\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=0-mse=0.23569999635219574\n",
      "### Validation result (epoch=0)\n",
      "  Phone level:  MSE=0.236  MAE=0.297  PCC=0.700 \n",
      "   Word level:  MSE=0.097  MAE=0.238  PCC=0.708 \n",
      "    Utt level:  MSE=0.066  MAE=0.199  PCC=0.739 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:48<00:00, 208.99it/s, loss=0.344, loss_phn=0.221, loss_utt=0.0512, loss_word=0.071, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87    462837\n",
      "         1.0       0.18      0.60      0.28     51044\n",
      "         2.0       0.85      0.31      0.45    100198\n",
      "\n",
      "    accuracy                           0.72    614079\n",
      "   macro avg       0.65      0.58      0.54    614079\n",
      "weighted avg       0.85      0.72      0.76    614079\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=1-mse=0.21780000627040863\n",
      "### Validation result (epoch=1)\n",
      "  Phone level:  MSE=0.218  MAE=0.294  PCC=0.731 \n",
      "   Word level:  MSE=0.090  MAE=0.226  PCC=0.737 \n",
      "    Utt level:  MSE=0.058  MAE=0.185  PCC=0.769 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:44<00:00, 227.07it/s, loss=0.416, loss_phn=0.173, loss_utt=0.114, loss_word=0.129, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.75      0.84    462842\n",
      "         1.0       0.18      0.67      0.28     51045\n",
      "         2.0       0.80      0.46      0.58    100199\n",
      "\n",
      "    accuracy                           0.69    614086\n",
      "   macro avg       0.64      0.62      0.56    614086\n",
      "weighted avg       0.86      0.69      0.75    614086\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=2-mse=0.20270000398159027\n",
      "### Validation result (epoch=2)\n",
      "  Phone level:  MSE=0.203  MAE=0.301  PCC=0.748 \n",
      "   Word level:  MSE=0.088  MAE=0.236  PCC=0.757 \n",
      "    Utt level:  MSE=0.057  MAE=0.193  PCC=0.784 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:44<00:00, 226.73it/s, loss=0.221, loss_phn=0.132, loss_utt=0.0414, loss_word=0.0476, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88    462839\n",
      "         1.0       0.20      0.52      0.28     51048\n",
      "         2.0       0.77      0.52      0.62    100198\n",
      "\n",
      "    accuracy                           0.75    614085\n",
      "   macro avg       0.63      0.62      0.59    614085\n",
      "weighted avg       0.85      0.75      0.79    614085\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=3-mse=0.19939999282360077\n",
      "### Validation result (epoch=3)\n",
      "  Phone level:  MSE=0.199  MAE=0.266  PCC=0.754 \n",
      "   Word level:  MSE=0.080  MAE=0.205  PCC=0.760 \n",
      "    Utt level:  MSE=0.051  MAE=0.172  PCC=0.789 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:51<00:00, 197.52it/s, loss=0.221, loss_phn=0.192, loss_utt=0.0141, loss_word=0.0157, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87    462846\n",
      "         1.0       0.20      0.62      0.30     51047\n",
      "         2.0       0.83      0.45      0.58    100199\n",
      "\n",
      "    accuracy                           0.74    614092\n",
      "   macro avg       0.66      0.63      0.58    614092\n",
      "weighted avg       0.86      0.74      0.78    614092\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=4-mse=0.18729999661445618\n",
      "### Validation result (epoch=4)\n",
      "  Phone level:  MSE=0.187  MAE=0.276  PCC=0.769 \n",
      "   Word level:  MSE=0.077  MAE=0.212  PCC=0.775 \n",
      "    Utt level:  MSE=0.049  MAE=0.174  PCC=0.801 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 223.04it/s, loss=0.348, loss_phn=0.238, loss_utt=0.0502, loss_word=0.0603, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87    462841\n",
      "         1.0       0.20      0.61      0.30     51046\n",
      "         2.0       0.83      0.46      0.59    100199\n",
      "\n",
      "    accuracy                           0.74    614086\n",
      "   macro avg       0.66      0.63      0.59    614086\n",
      "weighted avg       0.86      0.74      0.78    614086\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=5-mse=0.186599999666214\n",
      "### Validation result (epoch=5)\n",
      "  Phone level:  MSE=0.187  MAE=0.273  PCC=0.769 \n",
      "   Word level:  MSE=0.077  MAE=0.206  PCC=0.777 \n",
      "    Utt level:  MSE=0.051  MAE=0.171  PCC=0.798 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 224.02it/s, loss=0.241, loss_phn=0.161, loss_utt=0.0377, loss_word=0.0423, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.81      0.87    462818\n",
      "         1.0       0.20      0.62      0.30     51042\n",
      "         2.0       0.82      0.48      0.61    100199\n",
      "\n",
      "    accuracy                           0.74    614059\n",
      "   macro avg       0.66      0.64      0.59    614059\n",
      "weighted avg       0.86      0.74      0.78    614059\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=6-mse=0.18240000307559967\n",
      "### Validation result (epoch=6)\n",
      "  Phone level:  MSE=0.182  MAE=0.269  PCC=0.775 \n",
      "   Word level:  MSE=0.075  MAE=0.199  PCC=0.776 \n",
      "    Utt level:  MSE=0.049  MAE=0.165  PCC=0.807 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:44<00:00, 226.08it/s, loss=0.335, loss_phn=0.18, loss_utt=0.0722, loss_word=0.0836, lr=0.001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.78      0.86    462837\n",
      "         1.0       0.19      0.66      0.30     51045\n",
      "         2.0       0.84      0.47      0.60    100196\n",
      "\n",
      "    accuracy                           0.72    614078\n",
      "   macro avg       0.66      0.64      0.59    614078\n",
      "weighted avg       0.87      0.72      0.77    614078\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=7-mse=0.18129999935626984\n",
      "### Validation result (epoch=7)\n",
      "  Phone level:  MSE=0.181  MAE=0.281  PCC=0.778 \n",
      "   Word level:  MSE=0.073  MAE=0.208  PCC=0.787 \n",
      "    Utt level:  MSE=0.047  MAE=0.170  PCC=0.807 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 223.26it/s, loss=0.261, loss_phn=0.141, loss_utt=0.0493, loss_word=0.0704, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.79      0.86    462842\n",
      "         1.0       0.20      0.65      0.30     51048\n",
      "         2.0       0.83      0.50      0.62    100198\n",
      "\n",
      "    accuracy                           0.73    614088\n",
      "   macro avg       0.66      0.65      0.59    614088\n",
      "weighted avg       0.87      0.73      0.78    614088\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=8-mse=0.17820000648498535\n",
      "### Validation result (epoch=8)\n",
      "  Phone level:  MSE=0.178  MAE=0.276  PCC=0.782 \n",
      "   Word level:  MSE=0.080  MAE=0.224  PCC=0.791 \n",
      "    Utt level:  MSE=0.053  MAE=0.186  PCC=0.812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:50<00:00, 201.58it/s, loss=0.437, loss_phn=0.179, loss_utt=0.122, loss_word=0.135, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.79      0.87    462822\n",
      "         1.0       0.20      0.60      0.30     51049\n",
      "         2.0       0.79      0.58      0.67    100198\n",
      "\n",
      "    accuracy                           0.74    614069\n",
      "   macro avg       0.65      0.66      0.61    614069\n",
      "weighted avg       0.86      0.74      0.79    614069\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=9-mse=0.17730000615119934\n",
      "### Validation result (epoch=9)\n",
      "  Phone level:  MSE=0.177  MAE=0.265  PCC=0.785 \n",
      "   Word level:  MSE=0.071  MAE=0.198  PCC=0.794 \n",
      "    Utt level:  MSE=0.049  MAE=0.171  PCC=0.816 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [01:10<00:00, 143.81it/s, loss=0.277, loss_phn=0.154, loss_utt=0.0434, loss_word=0.0796, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90    462841\n",
      "         1.0       0.22      0.54      0.31     51043\n",
      "         2.0       0.83      0.51      0.63    100197\n",
      "\n",
      "    accuracy                           0.78    614081\n",
      "   macro avg       0.66      0.64      0.61    614081\n",
      "weighted avg       0.86      0.78      0.80    614081\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=10-mse=0.17499999701976776\n",
      "### Validation result (epoch=10)\n",
      "  Phone level:  MSE=0.175  MAE=0.244  PCC=0.787 \n",
      "   Word level:  MSE=0.070  MAE=0.191  PCC=0.797 \n",
      "    Utt level:  MSE=0.046  MAE=0.161  PCC=0.820 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 219.51it/s, loss=0.431, loss_phn=0.241, loss_utt=0.0896, loss_word=0.101, lr=0.001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.89    462838\n",
      "         1.0       0.21      0.56      0.31     51048\n",
      "         2.0       0.81      0.56      0.66    100194\n",
      "\n",
      "    accuracy                           0.77    614080\n",
      "   macro avg       0.65      0.65      0.62    614080\n",
      "weighted avg       0.86      0.77      0.80    614080\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=11-mse=0.17080000042915344\n",
      "### Validation result (epoch=11)\n",
      "  Phone level:  MSE=0.171  MAE=0.251  PCC=0.792 \n",
      "   Word level:  MSE=0.066  MAE=0.186  PCC=0.804 \n",
      "    Utt level:  MSE=0.044  MAE=0.159  PCC=0.826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 220.36it/s, loss=0.342, loss_phn=0.168, loss_utt=0.0828, loss_word=0.091, lr=0.0008]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.89    462823\n",
      "         1.0       0.21      0.60      0.32     51046\n",
      "         2.0       0.84      0.51      0.64    100199\n",
      "\n",
      "    accuracy                           0.76    614068\n",
      "   macro avg       0.67      0.65      0.61    614068\n",
      "weighted avg       0.87      0.76      0.80    614068\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=12-mse=0.16590000689029694\n",
      "### Validation result (epoch=12)\n",
      "  Phone level:  MSE=0.166  MAE=0.246  PCC=0.798 \n",
      "   Word level:  MSE=0.066  MAE=0.186  PCC=0.809 \n",
      "    Utt level:  MSE=0.043  MAE=0.157  PCC=0.828 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 222.13it/s, loss=0.132, loss_phn=0.0816, loss_utt=0.0205, loss_word=0.0296, lr=0.0008]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88    462842\n",
      "         1.0       0.21      0.62      0.31     51043\n",
      "         2.0       0.83      0.55      0.66    100196\n",
      "\n",
      "    accuracy                           0.76    614081\n",
      "   macro avg       0.66      0.66      0.62    614081\n",
      "weighted avg       0.87      0.76      0.80    614081\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=13-mse=0.163100004196167\n",
      "### Validation result (epoch=13)\n",
      "  Phone level:  MSE=0.163  MAE=0.253  PCC=0.802 \n",
      "   Word level:  MSE=0.064  MAE=0.185  PCC=0.814 \n",
      "    Utt level:  MSE=0.041  MAE=0.156  PCC=0.835 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 220.01it/s, loss=0.162, loss_phn=0.132, loss_utt=0.014, loss_word=0.0164, lr=0.0008]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.88    462834\n",
      "         1.0       0.21      0.61      0.32     51041\n",
      "         2.0       0.83      0.56      0.67    100190\n",
      "\n",
      "    accuracy                           0.76    614065\n",
      "   macro avg       0.66      0.66      0.62    614065\n",
      "weighted avg       0.87      0.76      0.80    614065\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=14-mse=0.16060000658035278\n",
      "### Validation result (epoch=14)\n",
      "  Phone level:  MSE=0.161  MAE=0.242  PCC=0.805 \n",
      "   Word level:  MSE=0.062  MAE=0.177  PCC=0.820 \n",
      "    Utt level:  MSE=0.040  MAE=0.151  PCC=0.841 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 223.80it/s, loss=0.332, loss_phn=0.232, loss_utt=0.0491, loss_word=0.0513, lr=0.00064]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.89    462825\n",
      "         1.0       0.22      0.60      0.32     51046\n",
      "         2.0       0.85      0.51      0.64    100196\n",
      "\n",
      "    accuracy                           0.77    614067\n",
      "   macro avg       0.67      0.65      0.62    614067\n",
      "weighted avg       0.87      0.77      0.80    614067\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=15-mse=0.1606999933719635\n",
      "### Validation result (epoch=15)\n",
      "  Phone level:  MSE=0.161  MAE=0.239  PCC=0.806 \n",
      "   Word level:  MSE=0.062  MAE=0.175  PCC=0.822 \n",
      "    Utt level:  MSE=0.040  MAE=0.147  PCC=0.845 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 221.20it/s, loss=0.208, loss_phn=0.0922, loss_utt=0.047, loss_word=0.0692, lr=0.00064]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90    462834\n",
      "         1.0       0.22      0.59      0.32     51044\n",
      "         2.0       0.85      0.53      0.65    100195\n",
      "\n",
      "    accuracy                           0.78    614073\n",
      "   macro avg       0.67      0.66      0.62    614073\n",
      "weighted avg       0.87      0.78      0.81    614073\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=16-mse=0.15850000083446503\n",
      "### Validation result (epoch=16)\n",
      "  Phone level:  MSE=0.159  MAE=0.238  PCC=0.809 \n",
      "   Word level:  MSE=0.060  MAE=0.179  PCC=0.826 \n",
      "    Utt level:  MSE=0.039  MAE=0.147  PCC=0.844 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [01:00<00:00, 167.26it/s, loss=0.204, loss_phn=0.148, loss_utt=0.0223, loss_word=0.0341, lr=0.00064]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89    462827\n",
      "         1.0       0.22      0.60      0.32     51045\n",
      "         2.0       0.84      0.54      0.66    100196\n",
      "\n",
      "    accuracy                           0.77    614068\n",
      "   macro avg       0.67      0.66      0.62    614068\n",
      "weighted avg       0.87      0.77      0.80    614068\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=17-mse=0.15940000116825104\n",
      "### Validation result (epoch=17)\n",
      "  Phone level:  MSE=0.159  MAE=0.241  PCC=0.807 \n",
      "   Word level:  MSE=0.063  MAE=0.179  PCC=0.822 \n",
      "    Utt level:  MSE=0.039  MAE=0.148  PCC=0.848 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [01:06<00:00, 151.71it/s, loss=0.252, loss_phn=0.165, loss_utt=0.045, loss_word=0.0419, lr=0.000512]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89    462840\n",
      "         1.0       0.22      0.61      0.32     51048\n",
      "         2.0       0.85      0.53      0.65    100202\n",
      "\n",
      "    accuracy                           0.77    614090\n",
      "   macro avg       0.67      0.66      0.62    614090\n",
      "weighted avg       0.87      0.77      0.80    614090\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=18-mse=0.15680000185966492\n",
      "### Validation result (epoch=18)\n",
      "  Phone level:  MSE=0.157  MAE=0.242  PCC=0.811 \n",
      "   Word level:  MSE=0.060  MAE=0.177  PCC=0.828 \n",
      "    Utt level:  MSE=0.038  MAE=0.147  PCC=0.852 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 217.08it/s, loss=0.2, loss_phn=0.114, loss_utt=0.0312, loss_word=0.055, lr=0.000512]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.81      0.88    462837\n",
      "         1.0       0.21      0.60      0.31     51048\n",
      "         2.0       0.82      0.60      0.69    100200\n",
      "\n",
      "    accuracy                           0.76    614085\n",
      "   macro avg       0.66      0.67      0.63    614085\n",
      "weighted avg       0.87      0.76      0.80    614085\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=19-mse=0.15629999339580536\n",
      "### Validation result (epoch=19)\n",
      "  Phone level:  MSE=0.156  MAE=0.243  PCC=0.812 \n",
      "   Word level:  MSE=0.058  MAE=0.175  PCC=0.833 \n",
      "    Utt level:  MSE=0.037  MAE=0.146  PCC=0.857 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 219.72it/s, loss=0.0664, loss_phn=0.0426, loss_utt=0.012, loss_word=0.0119, lr=0.000512]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90    462833\n",
      "         1.0       0.22      0.60      0.33     51047\n",
      "         2.0       0.86      0.54      0.66    100195\n",
      "\n",
      "    accuracy                           0.78    614075\n",
      "   macro avg       0.68      0.66      0.63    614075\n",
      "weighted avg       0.87      0.78      0.81    614075\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=20-mse=0.15369999408721924\n",
      "### Validation result (epoch=20)\n",
      "  Phone level:  MSE=0.154  MAE=0.241  PCC=0.815 \n",
      "   Word level:  MSE=0.057  MAE=0.172  PCC=0.835 \n",
      "    Utt level:  MSE=0.036  MAE=0.141  PCC=0.856 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 220.52it/s, loss=0.285, loss_phn=0.132, loss_utt=0.0797, loss_word=0.0729, lr=0.00041]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87    462832\n",
      "         1.0       0.21      0.64      0.32     51049\n",
      "         2.0       0.83      0.59      0.69    100200\n",
      "\n",
      "    accuracy                           0.76    614081\n",
      "   macro avg       0.67      0.68      0.63    614081\n",
      "weighted avg       0.88      0.76      0.80    614081\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=21-mse=0.15189999341964722\n",
      "### Validation result (epoch=21)\n",
      "  Phone level:  MSE=0.152  MAE=0.247  PCC=0.819 \n",
      "   Word level:  MSE=0.059  MAE=0.186  PCC=0.842 \n",
      "    Utt level:  MSE=0.038  MAE=0.153  PCC=0.865 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 220.56it/s, loss=0.212, loss_phn=0.161, loss_utt=0.0197, loss_word=0.0316, lr=0.00041]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89    462842\n",
      "         1.0       0.22      0.62      0.33     51045\n",
      "         2.0       0.85      0.56      0.67    100199\n",
      "\n",
      "    accuracy                           0.77    614086\n",
      "   macro avg       0.68      0.67      0.63    614086\n",
      "weighted avg       0.87      0.77      0.81    614086\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=22-mse=0.15000000596046448\n",
      "### Validation result (epoch=22)\n",
      "  Phone level:  MSE=0.150  MAE=0.240  PCC=0.820 \n",
      "   Word level:  MSE=0.055  MAE=0.168  PCC=0.842 \n",
      "    Utt level:  MSE=0.036  MAE=0.145  PCC=0.861 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:46<00:00, 218.31it/s, loss=0.185, loss_phn=0.149, loss_utt=0.0151, loss_word=0.0208, lr=0.00041]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89    462840\n",
      "         1.0       0.22      0.60      0.33     51045\n",
      "         2.0       0.84      0.57      0.68    100198\n",
      "\n",
      "    accuracy                           0.78    614083\n",
      "   macro avg       0.67      0.67      0.63    614083\n",
      "weighted avg       0.87      0.78      0.81    614083\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=23-mse=0.14869999885559082\n",
      "### Validation result (epoch=23)\n",
      "  Phone level:  MSE=0.149  MAE=0.232  PCC=0.821 \n",
      "   Word level:  MSE=0.054  MAE=0.168  PCC=0.844 \n",
      "    Utt level:  MSE=0.035  MAE=0.140  PCC=0.865 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10159/10159 [00:45<00:00, 221.58it/s, loss=0.215, loss_phn=0.166, loss_utt=0.0215, loss_word=0.0279, lr=0.000328]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89    462837\n",
      "         1.0       0.22      0.61      0.33     51046\n",
      "         2.0       0.85      0.57      0.68    100195\n",
      "\n",
      "    accuracy                           0.78    614078\n",
      "   macro avg       0.68      0.67      0.63    614078\n",
      "weighted avg       0.88      0.78      0.81    614078\n",
      "\n",
      "Save state dict and result to /data/codes/apa/train/exp/ckpts/dev/ckpts-eph=24-mse=0.14720000326633453\n",
      "### Validation result (epoch=24)\n",
      "  Phone level:  MSE=0.147  MAE=0.234  PCC=0.823 \n",
      "   Word level:  MSE=0.053  MAE=0.169  PCC=0.850 \n",
      "    Utt level:  MSE=0.033  MAE=0.139  PCC=0.872 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 25 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "\n",
    "cur_lr = lr\n",
    "for epoch in range(num_epoch):\n",
    "    if epoch >= 10 and epoch % 3 == 0:\n",
    "        cur_lr = (4 / 5) * cur_lr \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(dataloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids, features, phone_ids, word_ids, relative_positions,\\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long(), rel_pos=relative_positions.long())\n",
    "                \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gopt_model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            lr=cur_lr,\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        device=device,\n",
    "        optimizer=optimizer,\n",
    "        gopt_model=gopt_model, \n",
    "        testloader=dataloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n",
    "    global_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from src.utils.train import (\n",
    "    to_device,\n",
    "    load_data,\n",
    "    load_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '/data/codes/apa/train/exp/dev'\n",
    "\n",
    "ids, phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, \\\n",
    "    gops, relative_positions, wavlm_features_path = load_data(in_dir)\n",
    "\n",
    "dataset = PrepDataset(\n",
    "    ids, phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, relative_positions, wavlm_features_path)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=1, \n",
    "    num_workers=1,\n",
    "    shuffle=True, \n",
    "    drop_last=False, \n",
    "    pin_memory=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_dim=32\n",
    "# num_heads=1\n",
    "# depth=3\n",
    "# input_dim=855\n",
    "# num_phone=44\n",
    "# max_length=128\n",
    "\n",
    "# lr=1e-3\n",
    "# weight_decay=5e-7\n",
    "# betas=(0.95, 0.999)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# gopt_model = PrepModel(\n",
    "#     embed_dim=embed_dim, num_heads=num_heads, \n",
    "#     depth=depth, input_dim=input_dim, \n",
    "#     max_length=max_length, num_phone=num_phone, dropout=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = \"/data/codes/apa/train/exp/dev/ckpts-eph=25-mse=0.147599995136261/model.pt\"\n",
    "# state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "# gopt_model.eval()\n",
    "# gopt_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81277/81277 [01:44<00:00, 780.60it/s] \n"
     ]
    }
   ],
   "source": [
    "sample_ids = []\n",
    "prep_scores = []\n",
    "elsa_scores = []\n",
    "\n",
    "gopt_model.eval()\n",
    "for batch in tqdm(dataloader):\n",
    "    batch_ids, features, phone_ids, word_ids, relative_positions,\\\n",
    "        phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        phone_score = gopt_model.forwar_phn(\n",
    "            x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        phone_score = phone_score.squeeze(-1)\n",
    "        \n",
    "    assert phone_score.shape[0] == 1\n",
    "    \n",
    "    phone_ids = [f'{batch_ids[0]}_{index}' for index in range((phone_labels!=-1).sum())]\n",
    "    sample_ids += phone_ids\n",
    "\n",
    "    elsa_scores.append(phone_labels[phone_labels!=-1])\n",
    "    prep_scores.append(phone_score[phone_labels!=-1])\n",
    "\n",
    "elsa_scores = torch.concat(elsa_scores).cpu()\n",
    "prep_scores = torch.concat(prep_scores).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{in_dir}/id', \"w\") as f:\n",
    "    content = \"\\n\".join(sample_ids)\n",
    "    f.write(content)\n",
    "\n",
    "np.save(f'{in_dir}/infer-prep_scores.npy', prep_scores.numpy() * 50)\n",
    "np.save(f'{in_dir}/infer-elsa_scores.npy', elsa_scores.numpy() * 50)\n",
    "np.save(f'{in_dir}/infer-phone_ids.npy', sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/apa/train\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/apa/train\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.utils.train import (\n",
    "    convert_score_to_color\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_scores = np.load(f'{in_dir}/infer-prep_scores.npy')\n",
    "elsa_scores = np.load(f'{in_dir}/infer-elsa_scores.npy')\n",
    "ids = np.load(f'{in_dir}/infer-phone_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96    566712\n",
      "           1       0.01      0.01      0.01      1196\n",
      "           2       0.93      0.05      0.10     46208\n",
      "\n",
      "    accuracy                           0.93    614116\n",
      "   macro avg       0.62      0.35      0.36    614116\n",
      "weighted avg       0.93      0.93      0.90    614116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_decisions = convert_score_to_color(torch.from_numpy(prep_scores).clone())\n",
    "prep_decisions = prep_decisions.int().numpy()\n",
    "\n",
    "elsa_decisions = convert_score_to_color(torch.from_numpy(elsa_scores).clone())\n",
    "elsa_decisions = elsa_decisions.int().numpy()\n",
    "\n",
    "print(classification_report(y_true=elsa_decisions, y_pred=prep_decisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prep</th>\n",
       "      <th>elsa</th>\n",
       "      <th>prep_score</th>\n",
       "      <th>elsa_score</th>\n",
       "      <th>uid</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4638476_2_0</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>93.619156</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4638476</td>\n",
       "      <td>9.619156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4638476_2_1</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>96.730301</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4638476</td>\n",
       "      <td>2.269699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   prep   elsa  prep_score  elsa_score      uid      diff\n",
       "0  4638476_2_0  GREEN  GREEN   93.619156        84.0  4638476  9.619156\n",
       "1  4638476_2_1  GREEN  GREEN   96.730301        99.0  4638476  2.269699"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {0:\"GREEN\", 1:\"YELLOW\", 2:\"RED\"}\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": ids.tolist(),\n",
    "        \"prep\": prep_decisions.tolist(),\n",
    "        \"elsa\": elsa_decisions.tolist(),\n",
    "        \"prep_score\": prep_scores.tolist(),\n",
    "        \"elsa_score\": elsa_scores.tolist(),\n",
    "    }\n",
    ")\n",
    "\n",
    "df[\"prep\"] = df.prep.apply(lambda x: id2label[x])\n",
    "df[\"elsa\"] = df.elsa.apply(lambda x: id2label[x])\n",
    "df[\"uid\"] = df.id.apply(lambda x: x.split(\"_\")[0])\n",
    "df[\"diff\"] = np.abs(df[\"prep_score\"] - df[\"elsa_score\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10733\n",
      "8198\n"
     ]
    }
   ],
   "source": [
    "print(df.uid.nunique())\n",
    "print((df[df[\"diff\"] > 40].uid.value_counts() > 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614116, 7)\n",
      "(31273, 7)\n"
     ]
    }
   ],
   "source": [
    "ignore_samples = df[df[\"diff\"] > 30].uid.value_counts() > 1\n",
    "ignore_samples = ignore_samples[ignore_samples==True]\n",
    "\n",
    "filtered_samples = df[~df.uid.isin(ignore_samples.index)]\n",
    "print(df.shape)\n",
    "print(filtered_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_path = f\"{out_dir}/id\"\n",
    "with open(id_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(filtered_samples.uid.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/codes/apa/train/data/feats/train/train-data-type-12-filtered/id'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
