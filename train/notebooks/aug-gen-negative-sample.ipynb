{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import random\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_path = \"/data/codes/apa/train/resources/lexicon.txt\"\n",
    "lexicon = pd.read_csv(lexicon_path, names=[\"word\", \"arpa\"], sep=\"\\t\")\n",
    "lexicon.dropna(inplace=True)\n",
    "\n",
    "filtered_lexicon = []\n",
    "for name, group in lexicon.groupby(\"word\"):\n",
    "    if group.shape[0] > 1:\n",
    "        continue\n",
    "    filtered_lexicon.append(group)\n",
    "\n",
    "lexicon = pd.concat(filtered_lexicon)\n",
    "vocab = lexicon[\"word\"].tolist()\n",
    "lexicon = lexicon.set_index(\"word\")[\"arpa\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/apa/train/resources/same_pron_arpa_dict.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    same_pron_arpa_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/apa/train/prep_data/jsonl/info_qt_10_trainset.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153491/153491 [00:19<00:00, 7809.83it/s] \n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for line in tqdm(lines):\n",
    "    if len(line[\"raw\"].split()) > 1:\n",
    "        continue\n",
    "\n",
    "    is_valid = True\n",
    "    for score in line[\"phone_scores\"]:\n",
    "        if score < 90:\n",
    "            is_valid = False\n",
    "            break\n",
    "    \n",
    "    wav, sr = librosa.load(line[\"audio_path\"], sr=16000)\n",
    "    if wav.shape[0] / sr < 1.5:\n",
    "        continue\n",
    "    \n",
    "    if len(line[\"arpas\"]) > 6:\n",
    "        continue\n",
    "\n",
    "    if is_valid == False:\n",
    "        continue\n",
    "    data.append(line)\n",
    "\n",
    "random.shuffle(data)\n",
    "data = data[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(arpa_1, arpa_2):\n",
    "    arpa_1 = [re.sub(\"\\d\", \"\", arpa) for arpa in arpa_1]\n",
    "    arpa_2 = set([re.sub(\"\\d\", \"\", arpa) for arpa in arpa_2])\n",
    "\n",
    "    for arpa in arpa_1:\n",
    "        if arpa in arpa_2:\n",
    "            return False\n",
    "\n",
    "        if arpa not in same_pron_arpa_dict:\n",
    "            continue\n",
    "        tmp_arpa = same_pron_arpa_dict[arpa]\n",
    "\n",
    "        for arpa in arpa_2:\n",
    "            if arpa in tmp_arpa:\n",
    "                return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def gen_aug_data(sample, text, arpa):\n",
    "    augment_data = {}\n",
    "\n",
    "    augment_data[\"id\"] = f'{sample[\"id\"]}-aug'\n",
    "    augment_data[\"raw\"] = sample[\"raw\"]\n",
    "    augment_data[\"text\"] = text\n",
    "    augment_data[\"utt_id\"] = sample[\"utt_id\"]\n",
    "    augment_data[\"start_time\"] = sample[\"start_time\"]\n",
    "    augment_data[\"end_time\"] = sample[\"end_time\"]\n",
    "    augment_data[\"arpas\"] = arpa\n",
    "    augment_data[\"trans\"] = arpa #sample[\"arpas\"]\n",
    "    augment_data[\"phone_scores\"] = [0,] * len(sample[\"phone_scores\"])\n",
    "    augment_data[\"word_scores\"] = [0,]\n",
    "    augment_data[\"utterance_scores\"] = 0\n",
    "    augment_data[\"decisions\"] = sample[\"decisions\"]\n",
    "    augment_data[\"word_ids\"] = sample[\"word_ids\"]\n",
    "    augment_data[\"audio_path\"] = sample[\"audio_path\"]\n",
    "        # os.path.join(\n",
    "        #     os.path.dirname(sample[\"audio_path\"]),\n",
    "        #     f'{augment_data[\"id\"]}.wav')\n",
    "    \n",
    "    return augment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 190/9894 [00:00<00:05, 1898.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9894/9894 [00:06<00:00, 1456.39it/s]\n"
     ]
    }
   ],
   "source": [
    "max_length = 3\n",
    "augmented_datas = []\n",
    "\n",
    "for sample in tqdm(data):\n",
    "    origin_arpa = []\n",
    "    for arpa in sample[\"arpas\"]:\n",
    "        if arpa == \"AH0\":\n",
    "            origin_arpa.append(\"AX\")\n",
    "        else:\n",
    "            origin_arpa.append(arpa)\n",
    "\n",
    "    sample[\"arpas\"] = origin_arpa\n",
    "\n",
    "    augment_arpa = []\n",
    "\n",
    "    num_word = random.randint(1, max_length)\n",
    "\n",
    "    count = 0\n",
    "    text, arpas = [], []\n",
    "    while count < num_word:\n",
    "        random_word = random.choice(vocab)\n",
    "        random_arpa = lexicon[random_word]\n",
    "\n",
    "        augment_arpa = random_arpa.strip().split()\n",
    "        if len(augment_arpa) != len(origin_arpa):\n",
    "            continue\n",
    "\n",
    "        if is_valid(arpa_1=origin_arpa, arpa_2=augment_arpa) == True:\n",
    "            count += 1\n",
    "\n",
    "            text.append(random_word)\n",
    "            arpas.append(\" \".join(augment_arpa))\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    arpas = \" \".join(arpas).split()\n",
    "\n",
    "    augment_data = gen_aug_data(\n",
    "        sample=sample,\n",
    "        text=text,\n",
    "        arpa=arpas\n",
    "    )\n",
    "\n",
    "    augmented_datas.append(augment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9894/9894 [00:01<00:00, 6275.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for sample in tqdm(augmented_datas):\n",
    "    in_path = sample[\"audio_path\"]\n",
    "    out_path = f'/data/codes/apa/train/prep_data/wav/{sample[\"id\"]}.wav'\n",
    "\n",
    "    shutil.copy(src=in_path, dst=out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/apa/train/prep_data/raw_jsonl/info_qt_10_trainset-aug.jsonl\"\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in augmented_datas:\n",
    "        json_obj = json.dumps(sample, ensure_ascii=False)\n",
    "        f.write(f'{json_obj}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"3324420-aug\", \"raw\": \"however\", \"text\": \"MUCKLE CUNY MEANLY\", \"utt_id\": null, \"start_time\": null, \"end_time\": null, \"arpas\": [\"M\", \"AH1\", \"K\", \"AX\", \"L\", \"K\", \"Y\", \"UW1\", \"N\", \"IY0\", \"M\", \"IY1\", \"N\", \"L\", \"IY0\"], \"trans\": [\"M\", \"AH1\", \"K\", \"AX\", \"L\", \"K\", \"Y\", \"UW1\", \"N\", \"IY0\", \"M\", \"IY1\", \"N\", \"L\", \"IY0\"], \"phone_scores\": [0, 0, 0, 0, 0], \"word_scores\": [0], \"utterance_scores\": 0, \"decisions\": [2, 2, 2, 2, 2], \"word_ids\": [0, 0, 0, 0, 0], \"audio_path\": \"/data/audio_data/prep_submission_audio/10/3324420.wav\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
