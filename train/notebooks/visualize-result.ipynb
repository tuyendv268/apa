{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def fbeta_score(precision, recall, beta):\n",
    "    beta_squared = beta ** 2\n",
    "    numerator = (1 + beta_squared) * precision * recall\n",
    "    denominator = beta_squared * precision + recall\n",
    "    fbeta = numerator / denominator\n",
    "    return fbeta\n",
    "\n",
    "def classification_report_fbeta(y_true, y_pred, beta=0.5, target_names=['0', '1', '2']):\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    fbeta_scores = {}\n",
    "    for class_name, metrics in report.items():\n",
    "        if class_name == 'accuracy':\n",
    "            continue\n",
    "        precision = metrics['precision']\n",
    "        recall = metrics['recall']\n",
    "        fbeta = fbeta_score(precision, recall, beta)\n",
    "        fbeta_scores[class_name] = fbeta\n",
    "    \n",
    "    weighted_precision = report['weighted avg']['precision']\n",
    "    weighted_recall = report['weighted avg']['recall']\n",
    "    weighted_fbeta = fbeta_score(weighted_precision, weighted_recall, beta)\n",
    "\n",
    "    # Print the F0.5 score for each class\n",
    "    print(\"F0.5 scores per class:\")\n",
    "    for class_name, fbeta in fbeta_scores.items():\n",
    "        print(f\"{class_name}: {fbeta:.2f}\")\n",
    "    \n",
    "    return report, weighted_fbeta, fbeta_scores\n",
    "\n",
    "y_true = [0, 1, 0, 1, 1, 2]\n",
    "y_pred = [0, 0, 1, 1, 1, 2]\n",
    "report, weighted_fbeta, fbeta_scores = classification_report_fbeta(y_true, y_pred, beta=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=75/50, RED_YELLOW=30/50):\n",
    "    LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":2}\n",
    "    red_index = score < RED_YELLOW\n",
    "    yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "    green_index = score >= YELLOW_GREEN\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    print(index.shape, pred.shape, label.shape)\n",
    "    \n",
    "    return label[index], pred[index]\n",
    "def cal_f1(pred_path, label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    predicted = convert_score_to_color(torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    f_beta = classification_report_fbeta(y_true=actual, y_pred=predicted, beta=0.5, target_names=[\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    print(f_beta)\n",
    "    result = classification_report(y_true=actual, y_pred=predicted)\n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    print(result)\n",
    "    \n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    \n",
    "\n",
    "    return result, cm_display.plot(cmap='Blues')\n",
    "    \n",
    "pred_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/phn_pred.npy\"\n",
    "label_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/phn_label.npy\"\n",
    "\n",
    "res, cm_display = cal_f1(pred_path=pred_path, label_path=label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50)\n",
    "plt.title(\"Short sentence\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=75/50, RED_YELLOW=30/50):\n",
    "    LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":1}\n",
    "    red_index = score < RED_YELLOW\n",
    "    yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "    green_index = score >= YELLOW_GREEN\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    print(index.shape, pred.shape, label.shape)\n",
    "    \n",
    "    return label[index], pred[index]\n",
    "def cal_f1(pred_path, label_path, YELLOW_GREEN=70/50, RED_YELLOW=35/50):\n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    predicted = convert_score_to_color(torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    f_beta = classification_report_fbeta(y_true=actual, y_pred=predicted, beta=0.5, target_names=[\"GREEN\", \"YELLOW\"])\n",
    "    print(f_beta)\n",
    "    result = classification_report(y_true=actual, y_pred=predicted)\n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    print(result)\n",
    "    \n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\"])\n",
    "    \n",
    "\n",
    "    return result, cm_display.plot(cmap='Blues')\n",
    "    \n",
    "pred_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/phn_pred.npy\"\n",
    "label_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/phn_label.npy\"\n",
    "\n",
    "res, cm_display = cal_f1(pred_path=pred_path, label_path=label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50)\n",
    "plt.title(\"Short sentence\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    print(index.shape, pred.shape, label.shape)\n",
    "    \n",
    "    return label[index], pred[index]\n",
    "\n",
    "def cal_utt_acc(pred, label, threshold=10/50):\n",
    "    _temp = np.abs(pred-label)\n",
    "    \n",
    "    pred = _temp < threshold\n",
    "    label = np.ones_like(_temp)\n",
    "\n",
    "    print((pred == label).sum()/ label.shape)\n",
    "    \n",
    "    print(classification_report(y_true=label, y_pred=pred, zero_division=0))\n",
    "\n",
    "pred_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/utt_pred.npy\"\n",
    "label_path = \"/data/codes/apa/train/exps/test-short-v2/ckpts-eph=35-mse=0.15209999680519104/utt_label.npy\"\n",
    "label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "cal_utt_acc(pred=pred, label=label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
